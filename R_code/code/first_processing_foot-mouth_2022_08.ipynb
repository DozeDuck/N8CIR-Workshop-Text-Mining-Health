{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![UKDS Logo](images/UKDS_Logos_Col_Grey_300dpi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Text-mining: Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Pre-Processing-(summarised-version)\" data-toc-modified-id=\"Pre-Processing-(summarised-version)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Pre-Processing (summarised version)</a></span></li><li><span><a href=\"#Processing\" data-toc-modified-id=\"Processing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tokenisation\" data-toc-modified-id=\"Tokenisation-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Tokenisation</a></span></li><li><span><a href=\"#Standardising\" data-toc-modified-id=\"Standardising-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Standardising</a></span><ul class=\"toc-item\"><li><span><a href=\"#Remove-uppercase-letters\" data-toc-modified-id=\"Remove-uppercase-letters-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Remove uppercase letters</a></span></li><li><span><a href=\"#Spelling-correction\" data-toc-modified-id=\"Spelling-correction-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Spelling correction</a></span></li><li><span><a href=\"#Leila-to-do-if-wants-a-challenge:\" data-toc-modified-id=\"Leila-to-do-if-wants-a-challenge:-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Leila to do if wants a challenge:</a></span></li></ul></li><li><span><a href=\"#Extra-Spellcheck-issue!\" data-toc-modified-id=\"Extra-Spellcheck-issue!-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Extra Spellcheck issue!</a></span><ul class=\"toc-item\"><li><span><a href=\"#RegEx-replacements\" data-toc-modified-id=\"RegEx-replacements-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>RegEx replacements</a></span></li></ul></li><li><span><a href=\"#Removing-irrelevancies\" data-toc-modified-id=\"Removing-irrelevancies-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Removing irrelevancies</a></span><ul class=\"toc-item\"><li><span><a href=\"#Remove-punctuation\" data-toc-modified-id=\"Remove-punctuation-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Remove punctuation</a></span></li><li><span><a href=\"#Stopwords\" data-toc-modified-id=\"Stopwords-3.4.2\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>Stopwords</a></span></li></ul></li><li><span><a href=\"#Consolidation\" data-toc-modified-id=\"Consolidation-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Consolidation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stemming-words\" data-toc-modified-id=\"Stemming-words-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>Stemming words</a></span></li><li><span><a href=\"#Lemmatisation---IGNORE-FOR-NOW!\" data-toc-modified-id=\"Lemmatisation---IGNORE-FOR-NOW!-3.5.2\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>Lemmatisation - IGNORE FOR NOW!</a></span></li></ul></li></ul></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Conclusions</a></span></li><li><span><a href=\"#Further-reading-and-resources\" data-toc-modified-id=\"Further-reading-and-resources-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Further reading and resources</a></span></li><li><span><a href=\"#Summary-Code\" data-toc-modified-id=\"Summary-Code-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Summary Code</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There is a table of contents provided here at the top of the notebook, but you can also access this menu at any point by clicking the Table of Contents button on the top toolbar (an icon with four horizontal bars, if unsure hover your mouse over the buttons). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\L_Pel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                0  \\\n",
      "0           0  5407diary02.rtf   \n",
      "1           1  5407diary03.rtf   \n",
      "2           2  5407diary07.rtf   \n",
      "3           3  5407diary08.rtf   \n",
      "4           4  5407diary09.rtf   \n",
      "5           5  5407diary10.rtf   \n",
      "6           6  5407diary13.rtf   \n",
      "7           7  5407diary14.rtf   \n",
      "8           8  5407diary15.rtf   \n",
      "9           9  5407diary16.rtf   \n",
      "\n",
      "                                                   1  \n",
      "0  \\n\\nInformation about diarist\\nDate of birth: ...  \n",
      "1  Information about diarist\\nDate of birth: 1966...  \n",
      "2  \\n\\nInformation about diarist\\nDate of birth: ...  \n",
      "3  Information about diarist\\nDate of birth: 1963...  \n",
      "4  Information about diarist\\nDate of birth: 1981...  \n",
      "5  Information about diarist\\nDate of birth: 1937...  \n",
      "6  Information about diarist\\nDate of birth: 1947...  \n",
      "7  \\nInformation about diarist\\nDate of birth: 19...  \n",
      "8  Information about diarist\\nDate of birth: 1949...  \n",
      "9  \\nInformation about diarist\\nDate of birth: 19...  \n"
     ]
    }
   ],
   "source": [
    "# It is good practice to always start by importing the modules and packages you will need. \n",
    "\n",
    "import os                         # os is a module for navigating your machine (e.g., file directories).\n",
    "import nltk                       # nltk stands for natural language tool kit and is useful for text-mining. \n",
    "import re                         # re is for regular expressions, which we use later \n",
    "import pandas as pd               # we need pandas to import the foot_mouth_original.xls file\n",
    "! pip install xlrd                # apparently we also need xlrd to read the .xls file because pandas is not old school\n",
    "import xlrd                       # le sigh\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize    # importing the word_tokenize function from nltk\n",
    "\n",
    "foot_mouth_df = pd.read_csv ('../code/data/foot_mouth/text.csv')\n",
    "print(foot_mouth_df[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing (summarised version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns renamed :)\n",
      " \n",
      "DataFrames Successfully split!\n",
      "Data Column added..\n",
      "Gender column added...\n",
      "Occupation column added...\n",
      " \n",
      " EVERYTHING READY! :)\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\L_Pel\\AppData\\Local\\Temp\\ipykernel_19604\\2853703863.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_foot_mouth = diary_file.append(group_int_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5407diary02.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5407diary03.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1966...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5407diary07.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>6th January 2003</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5407diary08.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1963...</td>\n",
       "      <td>9th March 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5407diary09.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1981...</td>\n",
       "      <td>25th February 2002</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5407diary10.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1937...</td>\n",
       "      <td>11th March 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5407diary13.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1947...</td>\n",
       "      <td>18th March 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5407diary14.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5407diary15.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1949...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5407diary16.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>2000 for 2001</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5407diary17.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1936...</td>\n",
       "      <td>30th May 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>5407diary18.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>5407diary19.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>4th March 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>5407diary21.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>11 March 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>5407diary22.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>5407diary23.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>24th March 2001</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5407diary24.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5407diary26.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>6th January 2003</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5407diary27.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>5407diary28.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>13 May 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>5407diary29.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>16th September 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>5407diary30.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>4th September\\n2600</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>5407diary31.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>5407diary32.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>5407diary34.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>5407diary36.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>5407diary37.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>5407diary39.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>5407diary40.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>5407diary41.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>5407diary42.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>24th October 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>5407diary43.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>5407diary44.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>5407diary47.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>5407diary48.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>10 Feb 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>5407diary49.rtf</td>\n",
       "      <td>\\t\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>5407diary52.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>10th Feb 2003</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>5407diary53.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>5407diary54.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>5407diary55.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>5407fg01.rtf</td>\n",
       "      <td>\\nGroups Discussion with Members of  Farmers F...</td>\n",
       "      <td>17/12/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>5407fg02.rtf</td>\n",
       "      <td>Groups Discussion with Members of Small Busine...</td>\n",
       "      <td>23/01/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>5407fg03.rtf</td>\n",
       "      <td>\\n\\nGroups Discussion with Members of  Agricul...</td>\n",
       "      <td>31/02/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>5407fg04.rtf</td>\n",
       "      <td>\\nNO AUDIO RECORDING\\n\\nGroups Discussion with...</td>\n",
       "      <td>13/02/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>5407fg05.rtf</td>\n",
       "      <td>\\n\\nGroups Discussion with Community Group of ...</td>\n",
       "      <td>21/02/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>5407fg06.rtf</td>\n",
       "      <td>\\n\\nGroup Discussion Panel Members, Group 6 – ...</td>\n",
       "      <td>28/02/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>5407int02.rtf</td>\n",
       "      <td>\\nDate of Interview: 14/03/02\\n\\nInformation a...</td>\n",
       "      <td>14/03/02</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>5407int03.rtf</td>\n",
       "      <td>\\nDate of Interview: 08/03/02\\n\\nInformation a...</td>\n",
       "      <td>08/03/02</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>5407int07.rtf</td>\n",
       "      <td>\\nDate of Interview: 14/03/02\\n\\nInformation a...</td>\n",
       "      <td>14/03/02</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>5407int08.rtf</td>\n",
       "      <td>\\nDate of Interview: 06/03/02\\n\\nInformation a...</td>\n",
       "      <td>06/03/02</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>5407int09.rtf</td>\n",
       "      <td>\\nDate of Interview: 26/02/02\\n\\nInformation a...</td>\n",
       "      <td>26/02/02</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number         Filename  \\\n",
       "0        0  5407diary02.rtf   \n",
       "1        1  5407diary03.rtf   \n",
       "2        2  5407diary07.rtf   \n",
       "3        3  5407diary08.rtf   \n",
       "4        4  5407diary09.rtf   \n",
       "5        5  5407diary10.rtf   \n",
       "6        6  5407diary13.rtf   \n",
       "7        7  5407diary14.rtf   \n",
       "8        8  5407diary15.rtf   \n",
       "9        9  5407diary16.rtf   \n",
       "10      10  5407diary17.rtf   \n",
       "11      11  5407diary18.rtf   \n",
       "12      12  5407diary19.rtf   \n",
       "13      13  5407diary21.rtf   \n",
       "14      14  5407diary22.rtf   \n",
       "15      15  5407diary23.rtf   \n",
       "16      16  5407diary24.rtf   \n",
       "17      17  5407diary26.rtf   \n",
       "18      18  5407diary27.rtf   \n",
       "19      19  5407diary28.rtf   \n",
       "20      20  5407diary29.rtf   \n",
       "21      21  5407diary30.rtf   \n",
       "22      22  5407diary31.rtf   \n",
       "23      23  5407diary32.rtf   \n",
       "24      24  5407diary34.rtf   \n",
       "25      25  5407diary36.rtf   \n",
       "26      26  5407diary37.rtf   \n",
       "27      27  5407diary39.rtf   \n",
       "28      28  5407diary40.rtf   \n",
       "29      29  5407diary41.rtf   \n",
       "30      30  5407diary42.rtf   \n",
       "31      31  5407diary43.rtf   \n",
       "32      32  5407diary44.rtf   \n",
       "33      33  5407diary47.rtf   \n",
       "34      34  5407diary48.rtf   \n",
       "35      35  5407diary49.rtf   \n",
       "36      36  5407diary52.rtf   \n",
       "37      37  5407diary53.rtf   \n",
       "38      38  5407diary54.rtf   \n",
       "39      39  5407diary55.rtf   \n",
       "40      40     5407fg01.rtf   \n",
       "41      41     5407fg02.rtf   \n",
       "42      42     5407fg03.rtf   \n",
       "43      43     5407fg04.rtf   \n",
       "44      44     5407fg05.rtf   \n",
       "45      45     5407fg06.rtf   \n",
       "46      46    5407int02.rtf   \n",
       "47      47    5407int03.rtf   \n",
       "48      48    5407int07.rtf   \n",
       "49      49    5407int08.rtf   \n",
       "50      50    5407int09.rtf   \n",
       "\n",
       "                                      everything_else                Dates  \\\n",
       "0   \\n\\nInformation about diarist\\nDate of birth: ...                  NaN   \n",
       "1   Information about diarist\\nDate of birth: 1966...                  NaN   \n",
       "2   \\n\\nInformation about diarist\\nDate of birth: ...     6th January 2003   \n",
       "3   Information about diarist\\nDate of birth: 1963...       9th March 2002   \n",
       "4   Information about diarist\\nDate of birth: 1981...   25th February 2002   \n",
       "5   Information about diarist\\nDate of birth: 1937...      11th March 2002   \n",
       "6   Information about diarist\\nDate of birth: 1947...      18th March 2002   \n",
       "7   \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "8   Information about diarist\\nDate of birth: 1949...                  NaN   \n",
       "9   \\nInformation about diarist\\nDate of birth: 19...        2000 for 2001   \n",
       "10  Information about diarist\\nDate of birth: 1936...        30th May 2002   \n",
       "11  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "12  \\nInformation about diarist\\nDate of birth: 19...       4th March 2002   \n",
       "13  \\nInformation about diarist\\nDate of birth: 19...        11 March 2002   \n",
       "14  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "15  \\nInformation about diarist\\nDate of birth: 19...      24th March 2001   \n",
       "16  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "17  \\nInformation about diarist\\nDate of birth: 19...     6th January 2003   \n",
       "18  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "19  \\nInformation about diarist\\nDate of birth: 19...          13 May 2002   \n",
       "20  \\nInformation about diarist\\nDate of birth: 19...  16th September 2002   \n",
       "21  \\nInformation about diarist\\nDate of birth: 19...  4th September\\n2600   \n",
       "22  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "23  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "24  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "25  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "26  \\n\\nInformation about diarist\\nDate of birth: ...                  NaN   \n",
       "27  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "28  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "29  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "30  \\nInformation about diarist\\nDate of birth: 19...    24th October 2002   \n",
       "31  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "32  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "33  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "34  \\nInformation about diarist\\nDate of birth: 19...          10 Feb 2002   \n",
       "35  \\t\\nInformation about diarist\\nDate of birth: ...                  NaN   \n",
       "36  \\nInformation about diarist\\nDate of birth: 19...        10th Feb 2003   \n",
       "37  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "38  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "39  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "40  \\nGroups Discussion with Members of  Farmers F...             17/12/02   \n",
       "41  Groups Discussion with Members of Small Busine...             23/01/02   \n",
       "42  \\n\\nGroups Discussion with Members of  Agricul...             31/02/02   \n",
       "43  \\nNO AUDIO RECORDING\\n\\nGroups Discussion with...             13/02/02   \n",
       "44  \\n\\nGroups Discussion with Community Group of ...             21/02/02   \n",
       "45  \\n\\nGroup Discussion Panel Members, Group 6 – ...             28/02/02   \n",
       "46  \\nDate of Interview: 14/03/02\\n\\nInformation a...             14/03/02   \n",
       "47  \\nDate of Interview: 08/03/02\\n\\nInformation a...             08/03/02   \n",
       "48  \\nDate of Interview: 14/03/02\\n\\nInformation a...             14/03/02   \n",
       "49  \\nDate of Interview: 06/03/02\\n\\nInformation a...             06/03/02   \n",
       "50  \\nDate of Interview: 26/02/02\\n\\nInformation a...             26/02/02   \n",
       "\n",
       "   Gender Occupation  \n",
       "0       M    Group 6  \n",
       "1       F    Group 6  \n",
       "2       F    Group 6  \n",
       "3       M    Group 6  \n",
       "4       F    Group 5  \n",
       "5       M    Group 5  \n",
       "6       M    Group 5  \n",
       "7       F    Group 5  \n",
       "8       F    Group 5  \n",
       "9       M    Group 5  \n",
       "10      M    Group 5  \n",
       "11      F    Group 5  \n",
       "12      M    Group 4  \n",
       "13      M    Group 4  \n",
       "14      F    Group 4  \n",
       "15      M    Group 4  \n",
       "16      M    Group 4  \n",
       "17      M    Group 4  \n",
       "18      F    Group 3  \n",
       "19      M    Group 3  \n",
       "20      M    Group 3  \n",
       "21      M    Group 3  \n",
       "22      F    Group 3  \n",
       "23      M    Group 3  \n",
       "24      M    Group 3  \n",
       "25      M    Group 3  \n",
       "26      M    Group 2  \n",
       "27      F    Group 2  \n",
       "28      M    Group 2  \n",
       "29      M    Group 2  \n",
       "30      M    Group 2  \n",
       "31      F    Group 2  \n",
       "32      M    Group 4  \n",
       "33      M    Group 1  \n",
       "34      M    Group 1  \n",
       "35      F    Group 1  \n",
       "36      M    Group 1  \n",
       "37      M    Group 1  \n",
       "38      M    Group 1  \n",
       "39      F    Group 5  \n",
       "40    NaN    Group 1  \n",
       "41    NaN    Group 2  \n",
       "42    NaN    Group 3  \n",
       "43    NaN    Group 4  \n",
       "44    NaN    Group 5  \n",
       "45    NaN    Group 6  \n",
       "46      M    Group 6  \n",
       "47      F    Group 6  \n",
       "48      F    Group 6  \n",
       "49      M    Group 6  \n",
       "50      F    Group 5  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming Columns\n",
    "foot_mouth_df = pd.read_csv ('../code/data/foot_mouth/text.csv') \n",
    "\n",
    "foot_mouth_df.columns = [\"Number\", \"Filename\", \"everything_else\"]\n",
    "foot_mouth_df.head()\n",
    "\n",
    "print(\"Columns renamed :)\")\n",
    "print(\" \")\n",
    "\n",
    "# Splitting DataFrames\n",
    "diary_file = foot_mouth_df.loc[:39]     # Saving variable for all diary rows\n",
    "group_int_file = foot_mouth_df[40:]     # Saving variable for all group and interview rows\n",
    "\n",
    "print(\"DataFrames Successfully split!\")\n",
    "\n",
    "# Adding Data Column\n",
    "\n",
    "diary_file = diary_file.assign(Dates = diary_file['everything_else'].str.extract(r'(\\d{1,2}\\w+\\s+\\w+\\s+\\d{4})'))\n",
    "\n",
    "group_int_file = foot_mouth_df[40:]\n",
    "group_int_file = group_int_file.assign(Dates = group_int_file['everything_else'].str.extract(r'(\\d{2}\\/\\d{2}\\/\\d{2})'))\n",
    "\n",
    "new_foot_mouth = diary_file.append(group_int_file)\n",
    "\n",
    "print(\"Data Column added..\")\n",
    "\n",
    "# Assigning Gender Column then getting rid of the ':'\n",
    "\n",
    "new_foot_mouth = new_foot_mouth.assign(Gender = new_foot_mouth['everything_else'].str.extract('r(\\:\\s*[MF])')) \n",
    "\n",
    "# Changed this so that we preserve NaN values\n",
    "# Because you used astype(str), it converted NaN values in the Gender column to 'nan', a string value\n",
    "# Because new_foot_mouth['Gender'] is a series, we can use the str.strip method directly instead of applying astype(str) and map()\n",
    "# The str.strip method automatically ignores NaN values\n",
    "new_foot_mouth['Gender'] = new_foot_mouth['Gender'].str.strip(':')\n",
    "\n",
    "# new_foot_mouth['Gender'] = new_foot_mouth['Gender'].astype(str)\n",
    "# new_foot_mouth['Gender'] = new_foot_mouth['Gender'].map(lambda x: x.lstrip(':'))\n",
    "\n",
    "print(\"Gender column added...\")\n",
    "\n",
    "#Assigning the Occupation Column\n",
    "\n",
    "new_foot_mouth = new_foot_mouth.assign(Occupation = new_foot_mouth['everything_else'].str.extract(r'(\\w+\\s+\\d{1,2})'))\n",
    "\n",
    "print(\"Occupation column added...\")\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "print(\" EVERYTHING READY! :)\")\n",
    "print(\" \")\n",
    "\n",
    "new_foot_mouth.loc[:50]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________\n",
    "\n",
    "Processing steps\n",
    "- Tokenisation, (or splitting text into various kinds of 'short things' that can be statistically analysed).\n",
    "- Standardising the next (including converting uppercase to lower, correcting spelling, find-and-replace operations to remove abbreviations, etc.). \n",
    "- Removing irrelevancies (anything from punctuation to stopwords like 'the' or 'to' that are unhelpful for many kinds of analysis).\n",
    "- Consolidating (including stemming and lemmatisation that strip words back to their 'root'). \n",
    "- Basic NLP (that put some of the small things back together into logically useful medium things, like multi-word noun or verb phrases and proper names).\n",
    "\n",
    "In practice, most text-mining work will require that any given corpus undergo multiple steps, but the exact steps and the exact order of steps depends on the desired analysis to be done. Thus, some of the examples that follow will use the raw text corpus as an input to the process while others use a processed corpus as an input. \n",
    "\n",
    "As a side note, it is good practice to create new variables whenever you manipulate an existing variable rather than write over the original. This means that you keep the original and can go back to it anytime you need to if you want to try a different manipulation or correct an error. You will see how this works as we progress through the processing steps. \n",
    "\n",
    "**Since I am using this first type of processing to look for potential points for analysis, I will just stick to: word-tokenisation, basic standardisation and stemming**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to cut our 'one big thing' into tokens, or 'lots of little things'. As an example, one project I worked involved downloading a file with hundreds of recorded chess games, which I then divided into individual text files with one game each. The games had a very standard format, with every game ending with either '1-0', '0-1' or '1/2-1/2'. Thus, I was able to use regular expressions (covered in more detail later) to iterate over the file, selecting everyithing until it found an instance of '1-0', '0-1' or '1/2-1/2', at which point it would cut what it had selected, write it to a blank file, save it, and start iterating over the original file again. \n",
    "\n",
    "Other options that might make more sense with other kinds of files would be to to cut and write from the large file to new files after a specified number of lines or characters. \n",
    "\n",
    "Whether you have one big file or many smaller ones, most text-mining work will also want to divide the corpus into what are known as 'tokens'. These 'tokens' are the unit of analysis, which might be chapters, sections, paragraphs, sentences, words, or something else. \n",
    "\n",
    "Since we have one file already loaded as a corpus, we can skip the right to tokenising that text into sentences and words. Both options are functions available through the ntlk package that we imported earlier. These are both useful tokens in their own way, so we will see how to produce both kinds. \n",
    " \n",
    "We start by dividing our corpus into words, splitting the string into substrings whenever 'word_tokenize' detects a word. \n",
    "\n",
    "Let's try that. But this time, let's just have a look at the first 100 things it finds instead of the entire text.\n",
    "Run/Shift+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since this method takes basically adding columns every time we do a new step, I will do processing on original foot_mouth_df\n",
    "# Then I will append anything usefuul onto the modified 'new_foot_mouth' DataFrame for the extraction process!\n",
    "\n",
    "foot_mouth_df['tokenised_words'] = foot_mouth_df.apply(lambda row: nltk.word_tokenize(row['everything_else']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Information',\n",
       " 'about',\n",
       " 'diarist',\n",
       " 'Date',\n",
       " 'of',\n",
       " 'birth',\n",
       " ':',\n",
       " '1966',\n",
       " 'Gender',\n",
       " ':',\n",
       " 'F',\n",
       " 'Occupation',\n",
       " ':',\n",
       " 'Group',\n",
       " '6',\n",
       " 'Geographic',\n",
       " 'region',\n",
       " ':',\n",
       " 'North',\n",
       " 'Cumbria',\n",
       " 'Diary',\n",
       " '1',\n",
       " 'Monday',\n",
       " 'was',\n",
       " 'the',\n",
       " 'usual',\n",
       " 'long',\n",
       " 'hard',\n",
       " 'grind',\n",
       " '.',\n",
       " 'I',\n",
       " 'accept',\n",
       " 'that',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'put',\n",
       " 'in',\n",
       " '10',\n",
       " '–',\n",
       " '12',\n",
       " 'hours',\n",
       " 'and',\n",
       " 'I',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'mind',\n",
       " 'doing',\n",
       " 'the',\n",
       " 'work',\n",
       " 'because',\n",
       " 'it',\n",
       " '’',\n",
       " 's',\n",
       " 'not',\n",
       " 'physically',\n",
       " 'or',\n",
       " 'mentally',\n",
       " 'taxing',\n",
       " 'but',\n",
       " 'I',\n",
       " 'do',\n",
       " 'hate',\n",
       " 'not',\n",
       " 'having',\n",
       " 'a',\n",
       " 'lunch',\n",
       " 'break',\n",
       " ',',\n",
       " 'just',\n",
       " 'that',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'selfish',\n",
       " 'time',\n",
       " 'to',\n",
       " 'site',\n",
       " ',',\n",
       " 'have',\n",
       " 'a',\n",
       " 'cigarette',\n",
       " ',',\n",
       " 'take',\n",
       " 'the',\n",
       " 'dogs',\n",
       " 'down',\n",
       " 'the',\n",
       " 'river',\n",
       " ',',\n",
       " 'see',\n",
       " 'the',\n",
       " 'horses…whatever',\n",
       " '.',\n",
       " 'I',\n",
       " 'do',\n",
       " 'resent',\n",
       " 'that',\n",
       " 'fact']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foot_mouth_df['tokenised_words'][1][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since I am using this first type of processing to look for potential points for analysis, I will just stick to \n",
    "# word-tokenisation, basic standardisation and stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[IGNORE FOR NOW]**\n",
    "\n",
    "Let's have a look. \n",
    "\n",
    "We can see that corpus_words is a list of strings. We know it is a list because it starts and ends with square brackets and we know the things in that list are strings because they are surrounded by single quotes. \n",
    "\n",
    "We can also see that puctuation marks are counted as tokens in that list. For example, the full stop at the end of the first sentence appears as its own token because word_tokenize knows that it does not count as part of the previous word. Interestingly, 'U.K.' is all one token, despite having full stops in. Clever stuff, this tokenisation function!\n",
    "\n",
    "Word_tokenize is a useful function if you want to take a 'bag of words' approach to text-mining. This reduces a lot of the contextual information within the original corpus because it ignores how the words were used or in what order they originally appeared, making it easy to count how often each word occurrs. There is a surprising amount of insight to be gained here, but it does mean that 'building' in the next two sentences will be counted as the \"same\" word. \n",
    "- \"He is building a diorama for a school project.\" where 'building' is a verb\n",
    "- \"The building is a clear example of brutalist architecture.\" where 'building' is a noun\n",
    "\n",
    "There are other kinds of analyses that you could do if you want verb-building and noun-building to be counted as different words. That usually starts with tokenising differently, for example into sentences rather than words. \n",
    "Let's see what that looks like by running the same basic analysis again, but this time with sentence-token things instead of word-token things. \n",
    "\n",
    "Do that funky Run/Shift+Enter thing! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [IGNORE FOR NOW]\n",
    "\n",
    "# importing sent_tokenize from nltk\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# Same again, but this time broken into sentences\n",
    "corpus_sentences = sent_tokenize(corpus)\n",
    "print(corpus_sentences[:10])                                                  # Since these are sentences instead of words, \n",
    "                                                                              # we only want the first 10 items instead of 100.\n",
    "print(\"...\")                                                                  \n",
    "type(corpus_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising\n",
    "#### Remove uppercase letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to focus on the 'bag of words' approach, we don't really care about uppercase or lowercase distinctions. For example, we want 'Privacy' to count as the same word as 'privacy', rather than as two different words. \n",
    "\n",
    "We can remove all uppercase letters with a built in python command on corpus_words. Do this in the next code cell, again returning just the first 100 items instead of the whole thing. \n",
    "\n",
    "Do the Run/Shift+Enter thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see that I created a new variable called corpus_lower rather than edit corpus_words directly.\n",
    "# This means I can easily compare two different processes or correct something without going back and re-running earlier steps. \n",
    "\n",
    "foot_mouth_df['txt_lower'] = foot_mouth_df['tokenised_words'].apply(lambda x: [w.lower() for w in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>tokenised_words</th>\n",
       "      <th>txt_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5407diary02.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5407diary03.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1966...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5407diary07.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5407diary08.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1963...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5407diary09.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1981...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5407diary10.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1937...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5407diary13.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1947...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5407diary14.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5407diary15.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1949...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5407diary16.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5407diary17.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1936...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>5407diary18.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>5407diary19.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>5407diary21.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>5407diary22.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>5407diary23.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5407diary24.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5407diary26.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5407diary27.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>5407diary28.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>5407diary29.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>5407diary30.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>5407diary31.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>5407diary32.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>5407diary34.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>5407diary36.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>5407diary37.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>5407diary39.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>5407diary40.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>5407diary41.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>5407diary42.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>5407diary43.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>5407diary44.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>5407diary47.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>5407diary48.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>5407diary49.rtf</td>\n",
       "      <td>\\t\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>5407diary52.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>5407diary53.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>5407diary54.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>5407diary55.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>5407fg01.rtf</td>\n",
       "      <td>\\nGroups Discussion with Members of  Farmers F...</td>\n",
       "      <td>[Groups, Discussion, with, Members, of, Farmer...</td>\n",
       "      <td>[groups, discussion, with, members, of, farmer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>5407fg02.rtf</td>\n",
       "      <td>Groups Discussion with Members of Small Busine...</td>\n",
       "      <td>[Groups, Discussion, with, Members, of, Small,...</td>\n",
       "      <td>[groups, discussion, with, members, of, small,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>5407fg03.rtf</td>\n",
       "      <td>\\n\\nGroups Discussion with Members of  Agricul...</td>\n",
       "      <td>[Groups, Discussion, with, Members, of, Agricu...</td>\n",
       "      <td>[groups, discussion, with, members, of, agricu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>5407fg04.rtf</td>\n",
       "      <td>\\nNO AUDIO RECORDING\\n\\nGroups Discussion with...</td>\n",
       "      <td>[NO, AUDIO, RECORDING, Groups, Discussion, wit...</td>\n",
       "      <td>[no, audio, recording, groups, discussion, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>5407fg05.rtf</td>\n",
       "      <td>\\n\\nGroups Discussion with Community Group of ...</td>\n",
       "      <td>[Groups, Discussion, with, Community, Group, o...</td>\n",
       "      <td>[groups, discussion, with, community, group, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>5407fg06.rtf</td>\n",
       "      <td>\\n\\nGroup Discussion Panel Members, Group 6 – ...</td>\n",
       "      <td>[Group, Discussion, Panel, Members, ,, Group, ...</td>\n",
       "      <td>[group, discussion, panel, members, ,, group, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>5407int02.rtf</td>\n",
       "      <td>\\nDate of Interview: 14/03/02\\n\\nInformation a...</td>\n",
       "      <td>[Date, of, Interview, :, 14/03/02, Information...</td>\n",
       "      <td>[date, of, interview, :, 14/03/02, information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>5407int03.rtf</td>\n",
       "      <td>\\nDate of Interview: 08/03/02\\n\\nInformation a...</td>\n",
       "      <td>[Date, of, Interview, :, 08/03/02, Information...</td>\n",
       "      <td>[date, of, interview, :, 08/03/02, information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>5407int07.rtf</td>\n",
       "      <td>\\nDate of Interview: 14/03/02\\n\\nInformation a...</td>\n",
       "      <td>[Date, of, Interview, :, 14/03/02, Information...</td>\n",
       "      <td>[date, of, interview, :, 14/03/02, information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>5407int08.rtf</td>\n",
       "      <td>\\nDate of Interview: 06/03/02\\n\\nInformation a...</td>\n",
       "      <td>[Date, of, Interview, :, 06/03/02, Information...</td>\n",
       "      <td>[date, of, interview, :, 06/03/02, information...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number         Filename  \\\n",
       "0        0  5407diary02.rtf   \n",
       "1        1  5407diary03.rtf   \n",
       "2        2  5407diary07.rtf   \n",
       "3        3  5407diary08.rtf   \n",
       "4        4  5407diary09.rtf   \n",
       "5        5  5407diary10.rtf   \n",
       "6        6  5407diary13.rtf   \n",
       "7        7  5407diary14.rtf   \n",
       "8        8  5407diary15.rtf   \n",
       "9        9  5407diary16.rtf   \n",
       "10      10  5407diary17.rtf   \n",
       "11      11  5407diary18.rtf   \n",
       "12      12  5407diary19.rtf   \n",
       "13      13  5407diary21.rtf   \n",
       "14      14  5407diary22.rtf   \n",
       "15      15  5407diary23.rtf   \n",
       "16      16  5407diary24.rtf   \n",
       "17      17  5407diary26.rtf   \n",
       "18      18  5407diary27.rtf   \n",
       "19      19  5407diary28.rtf   \n",
       "20      20  5407diary29.rtf   \n",
       "21      21  5407diary30.rtf   \n",
       "22      22  5407diary31.rtf   \n",
       "23      23  5407diary32.rtf   \n",
       "24      24  5407diary34.rtf   \n",
       "25      25  5407diary36.rtf   \n",
       "26      26  5407diary37.rtf   \n",
       "27      27  5407diary39.rtf   \n",
       "28      28  5407diary40.rtf   \n",
       "29      29  5407diary41.rtf   \n",
       "30      30  5407diary42.rtf   \n",
       "31      31  5407diary43.rtf   \n",
       "32      32  5407diary44.rtf   \n",
       "33      33  5407diary47.rtf   \n",
       "34      34  5407diary48.rtf   \n",
       "35      35  5407diary49.rtf   \n",
       "36      36  5407diary52.rtf   \n",
       "37      37  5407diary53.rtf   \n",
       "38      38  5407diary54.rtf   \n",
       "39      39  5407diary55.rtf   \n",
       "40      40     5407fg01.rtf   \n",
       "41      41     5407fg02.rtf   \n",
       "42      42     5407fg03.rtf   \n",
       "43      43     5407fg04.rtf   \n",
       "44      44     5407fg05.rtf   \n",
       "45      45     5407fg06.rtf   \n",
       "46      46    5407int02.rtf   \n",
       "47      47    5407int03.rtf   \n",
       "48      48    5407int07.rtf   \n",
       "49      49    5407int08.rtf   \n",
       "\n",
       "                                      everything_else  \\\n",
       "0   \\n\\nInformation about diarist\\nDate of birth: ...   \n",
       "1   Information about diarist\\nDate of birth: 1966...   \n",
       "2   \\n\\nInformation about diarist\\nDate of birth: ...   \n",
       "3   Information about diarist\\nDate of birth: 1963...   \n",
       "4   Information about diarist\\nDate of birth: 1981...   \n",
       "5   Information about diarist\\nDate of birth: 1937...   \n",
       "6   Information about diarist\\nDate of birth: 1947...   \n",
       "7   \\nInformation about diarist\\nDate of birth: 19...   \n",
       "8   Information about diarist\\nDate of birth: 1949...   \n",
       "9   \\nInformation about diarist\\nDate of birth: 19...   \n",
       "10  Information about diarist\\nDate of birth: 1936...   \n",
       "11  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "12  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "13  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "14  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "15  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "16  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "17  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "18  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "19  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "20  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "21  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "22  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "23  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "24  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "25  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "26  \\n\\nInformation about diarist\\nDate of birth: ...   \n",
       "27  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "28  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "29  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "30  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "31  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "32  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "33  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "34  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "35  \\t\\nInformation about diarist\\nDate of birth: ...   \n",
       "36  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "37  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "38  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "39  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "40  \\nGroups Discussion with Members of  Farmers F...   \n",
       "41  Groups Discussion with Members of Small Busine...   \n",
       "42  \\n\\nGroups Discussion with Members of  Agricul...   \n",
       "43  \\nNO AUDIO RECORDING\\n\\nGroups Discussion with...   \n",
       "44  \\n\\nGroups Discussion with Community Group of ...   \n",
       "45  \\n\\nGroup Discussion Panel Members, Group 6 – ...   \n",
       "46  \\nDate of Interview: 14/03/02\\n\\nInformation a...   \n",
       "47  \\nDate of Interview: 08/03/02\\n\\nInformation a...   \n",
       "48  \\nDate of Interview: 14/03/02\\n\\nInformation a...   \n",
       "49  \\nDate of Interview: 06/03/02\\n\\nInformation a...   \n",
       "\n",
       "                                      tokenised_words  \\\n",
       "0   [Information, about, diarist, Date, of, birth,...   \n",
       "1   [Information, about, diarist, Date, of, birth,...   \n",
       "2   [Information, about, diarist, Date, of, birth,...   \n",
       "3   [Information, about, diarist, Date, of, birth,...   \n",
       "4   [Information, about, diarist, Date, of, birth,...   \n",
       "5   [Information, about, diarist, Date, of, birth,...   \n",
       "6   [Information, about, diarist, Date, of, birth,...   \n",
       "7   [Information, about, diarist, Date, of, birth,...   \n",
       "8   [Information, about, diarist, Date, of, birth,...   \n",
       "9   [Information, about, diarist, Date, of, birth,...   \n",
       "10  [Information, about, diarist, Date, of, birth,...   \n",
       "11  [Information, about, diarist, Date, of, birth,...   \n",
       "12  [Information, about, diarist, Date, of, birth,...   \n",
       "13  [Information, about, diarist, Date, of, birth,...   \n",
       "14  [Information, about, diarist, Date, of, birth,...   \n",
       "15  [Information, about, diarist, Date, of, birth,...   \n",
       "16  [Information, about, diarist, Date, of, birth,...   \n",
       "17  [Information, about, diarist, Date, of, birth,...   \n",
       "18  [Information, about, diarist, Date, of, birth,...   \n",
       "19  [Information, about, diarist, Date, of, birth,...   \n",
       "20  [Information, about, diarist, Date, of, birth,...   \n",
       "21  [Information, about, diarist, Date, of, birth,...   \n",
       "22  [Information, about, diarist, Date, of, birth,...   \n",
       "23  [Information, about, diarist, Date, of, birth,...   \n",
       "24  [Information, about, diarist, Date, of, birth,...   \n",
       "25  [Information, about, diarist, Date, of, birth,...   \n",
       "26  [Information, about, diarist, Date, of, birth,...   \n",
       "27  [Information, about, diarist, Date, of, birth,...   \n",
       "28  [Information, about, diarist, Date, of, birth,...   \n",
       "29  [Information, about, diarist, Date, of, birth,...   \n",
       "30  [Information, about, diarist, Date, of, birth,...   \n",
       "31  [Information, about, diarist, Date, of, birth,...   \n",
       "32  [Information, about, diarist, Date, of, birth,...   \n",
       "33  [Information, about, diarist, Date, of, birth,...   \n",
       "34  [Information, about, diarist, Date, of, birth,...   \n",
       "35  [Information, about, diarist, Date, of, birth,...   \n",
       "36  [Information, about, diarist, Date, of, birth,...   \n",
       "37  [Information, about, diarist, Date, of, birth,...   \n",
       "38  [Information, about, diarist, Date, of, birth,...   \n",
       "39  [Information, about, diarist, Date, of, birth,...   \n",
       "40  [Groups, Discussion, with, Members, of, Farmer...   \n",
       "41  [Groups, Discussion, with, Members, of, Small,...   \n",
       "42  [Groups, Discussion, with, Members, of, Agricu...   \n",
       "43  [NO, AUDIO, RECORDING, Groups, Discussion, wit...   \n",
       "44  [Groups, Discussion, with, Community, Group, o...   \n",
       "45  [Group, Discussion, Panel, Members, ,, Group, ...   \n",
       "46  [Date, of, Interview, :, 14/03/02, Information...   \n",
       "47  [Date, of, Interview, :, 08/03/02, Information...   \n",
       "48  [Date, of, Interview, :, 14/03/02, Information...   \n",
       "49  [Date, of, Interview, :, 06/03/02, Information...   \n",
       "\n",
       "                                            txt_lower  \n",
       "0   [information, about, diarist, date, of, birth,...  \n",
       "1   [information, about, diarist, date, of, birth,...  \n",
       "2   [information, about, diarist, date, of, birth,...  \n",
       "3   [information, about, diarist, date, of, birth,...  \n",
       "4   [information, about, diarist, date, of, birth,...  \n",
       "5   [information, about, diarist, date, of, birth,...  \n",
       "6   [information, about, diarist, date, of, birth,...  \n",
       "7   [information, about, diarist, date, of, birth,...  \n",
       "8   [information, about, diarist, date, of, birth,...  \n",
       "9   [information, about, diarist, date, of, birth,...  \n",
       "10  [information, about, diarist, date, of, birth,...  \n",
       "11  [information, about, diarist, date, of, birth,...  \n",
       "12  [information, about, diarist, date, of, birth,...  \n",
       "13  [information, about, diarist, date, of, birth,...  \n",
       "14  [information, about, diarist, date, of, birth,...  \n",
       "15  [information, about, diarist, date, of, birth,...  \n",
       "16  [information, about, diarist, date, of, birth,...  \n",
       "17  [information, about, diarist, date, of, birth,...  \n",
       "18  [information, about, diarist, date, of, birth,...  \n",
       "19  [information, about, diarist, date, of, birth,...  \n",
       "20  [information, about, diarist, date, of, birth,...  \n",
       "21  [information, about, diarist, date, of, birth,...  \n",
       "22  [information, about, diarist, date, of, birth,...  \n",
       "23  [information, about, diarist, date, of, birth,...  \n",
       "24  [information, about, diarist, date, of, birth,...  \n",
       "25  [information, about, diarist, date, of, birth,...  \n",
       "26  [information, about, diarist, date, of, birth,...  \n",
       "27  [information, about, diarist, date, of, birth,...  \n",
       "28  [information, about, diarist, date, of, birth,...  \n",
       "29  [information, about, diarist, date, of, birth,...  \n",
       "30  [information, about, diarist, date, of, birth,...  \n",
       "31  [information, about, diarist, date, of, birth,...  \n",
       "32  [information, about, diarist, date, of, birth,...  \n",
       "33  [information, about, diarist, date, of, birth,...  \n",
       "34  [information, about, diarist, date, of, birth,...  \n",
       "35  [information, about, diarist, date, of, birth,...  \n",
       "36  [information, about, diarist, date, of, birth,...  \n",
       "37  [information, about, diarist, date, of, birth,...  \n",
       "38  [information, about, diarist, date, of, birth,...  \n",
       "39  [information, about, diarist, date, of, birth,...  \n",
       "40  [groups, discussion, with, members, of, farmer...  \n",
       "41  [groups, discussion, with, members, of, small,...  \n",
       "42  [groups, discussion, with, members, of, agricu...  \n",
       "43  [no, audio, recording, groups, discussion, wit...  \n",
       "44  [groups, discussion, with, community, group, o...  \n",
       "45  [group, discussion, panel, members, ,, group, ...  \n",
       "46  [date, of, interview, :, 14/03/02, information...  \n",
       "47  [date, of, interview, :, 08/03/02, information...  \n",
       "48  [date, of, interview, :, 14/03/02, information...  \n",
       "49  [date, of, interview, :, 06/03/02, information...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foot_mouth_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['information',\n",
       " 'about',\n",
       " 'diarist',\n",
       " 'date',\n",
       " 'of',\n",
       " 'birth',\n",
       " ':',\n",
       " '1964',\n",
       " 'gender',\n",
       " ':',\n",
       " 'f',\n",
       " 'occupation',\n",
       " ':',\n",
       " 'group',\n",
       " '6',\n",
       " 'geographic',\n",
       " 'region',\n",
       " ':',\n",
       " 'north',\n",
       " 'cumbria',\n",
       " 'week',\n",
       " 'beginning',\n",
       " '4th',\n",
       " 'march',\n",
       " '02',\n",
       " 'monday',\n",
       " '4th',\n",
       " 'march',\n",
       " 'we',\n",
       " 'decided',\n",
       " 'we',\n",
       " 'now',\n",
       " 'need',\n",
       " 'more',\n",
       " 'staff',\n",
       " ',',\n",
       " 'a',\n",
       " 'new',\n",
       " 'vet',\n",
       " 'and',\n",
       " 'a',\n",
       " 'part',\n",
       " 'time',\n",
       " 'receptionist',\n",
       " ',',\n",
       " 'this',\n",
       " 'could',\n",
       " 'take',\n",
       " 'us',\n",
       " 'back',\n",
       " 'up',\n",
       " 'to',\n",
       " 'our',\n",
       " 'previous',\n",
       " 'staffing',\n",
       " 'level',\n",
       " 'pre',\n",
       " 'fm',\n",
       " ',',\n",
       " 'bar',\n",
       " 'a',\n",
       " 'vet',\n",
       " '.',\n",
       " 'but',\n",
       " 'this',\n",
       " 'was',\n",
       " 'probably',\n",
       " 'going',\n",
       " 'to',\n",
       " 'be',\n",
       " 'all',\n",
       " 'the',\n",
       " 'recruitments',\n",
       " 'we',\n",
       " 'would',\n",
       " 'make',\n",
       " 'this',\n",
       " 'year',\n",
       " '.',\n",
       " 'it',\n",
       " '’',\n",
       " 's',\n",
       " 'a',\n",
       " 'good',\n",
       " 'sign',\n",
       " 'as',\n",
       " 'things',\n",
       " 'begin',\n",
       " 'to',\n",
       " 'get',\n",
       " 'back',\n",
       " 'to',\n",
       " 'normal',\n",
       " '!',\n",
       " '!',\n",
       " 'work',\n",
       " 'is',\n",
       " 'increasing',\n",
       " 'quite',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'now',\n",
       " 'most',\n",
       " 'of',\n",
       " 'our',\n",
       " 'farmers',\n",
       " 'have',\n",
       " 'restocked',\n",
       " ',',\n",
       " 'although',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'them',\n",
       " 'and',\n",
       " 'us',\n",
       " 'are',\n",
       " 'still',\n",
       " 'concerned',\n",
       " 'about',\n",
       " 'the',\n",
       " 'future',\n",
       " '.',\n",
       " 'tuesday',\n",
       " '5th',\n",
       " 'march',\n",
       " 'a',\n",
       " 'difficult',\n",
       " 'day',\n",
       " 'today',\n",
       " 'with',\n",
       " 'licences',\n",
       " ',',\n",
       " 'two',\n",
       " 'of',\n",
       " 'our',\n",
       " 'farmers',\n",
       " 'needed',\n",
       " 'sole',\n",
       " 'occupancy',\n",
       " 'authentitys',\n",
       " '(',\n",
       " 'soa',\n",
       " ')',\n",
       " 'and',\n",
       " 'there',\n",
       " 'were',\n",
       " 'queries',\n",
       " 'with',\n",
       " 'their',\n",
       " 'land',\n",
       " ',',\n",
       " 'unless',\n",
       " 'some',\n",
       " 'of',\n",
       " 'their',\n",
       " 'fields',\n",
       " 'could',\n",
       " 'be',\n",
       " 'redefined',\n",
       " ',',\n",
       " 'they',\n",
       " 'were',\n",
       " 'worried',\n",
       " 'their',\n",
       " 'stock',\n",
       " 'would',\n",
       " 'suffer',\n",
       " '.',\n",
       " 'during',\n",
       " 'the',\n",
       " 'fm',\n",
       " 'these',\n",
       " 'worries',\n",
       " 'have',\n",
       " 'shown',\n",
       " 'how',\n",
       " 'much',\n",
       " 'they',\n",
       " 'care',\n",
       " 'about',\n",
       " 'their',\n",
       " 'stock',\n",
       " 'and',\n",
       " 'find',\n",
       " 'it',\n",
       " 'very',\n",
       " 'frustrating',\n",
       " 'when',\n",
       " 'they',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'understand',\n",
       " 'why',\n",
       " 'we',\n",
       " 'can',\n",
       " '’',\n",
       " 't',\n",
       " 'move',\n",
       " 'them',\n",
       " ',',\n",
       " 'even',\n",
       " 'to',\n",
       " 'the',\n",
       " 'point',\n",
       " 'of',\n",
       " 'anger',\n",
       " 'and',\n",
       " 'tears',\n",
       " '.',\n",
       " 'by',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'the',\n",
       " 'day',\n",
       " ',',\n",
       " 'thankfully',\n",
       " 'they',\n",
       " 'were',\n",
       " 'resolved',\n",
       " ',',\n",
       " 'with',\n",
       " 'compromise',\n",
       " 'on',\n",
       " 'both',\n",
       " 'sides',\n",
       " 'and',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'phone',\n",
       " 'calls',\n",
       " '.',\n",
       " 'wednesday',\n",
       " '6th',\n",
       " 'march',\n",
       " 'i',\n",
       " 'decided',\n",
       " 'to',\n",
       " 'sort',\n",
       " 'out',\n",
       " 'all',\n",
       " 'the',\n",
       " 'paperwork',\n",
       " 'and',\n",
       " 'guidelines',\n",
       " 'we',\n",
       " 'had',\n",
       " 'received',\n",
       " 'from',\n",
       " 'defra',\n",
       " 'over',\n",
       " 'the',\n",
       " 'past',\n",
       " 'twelve',\n",
       " 'months',\n",
       " '–',\n",
       " 'it',\n",
       " 'was',\n",
       " 'quite',\n",
       " 'a',\n",
       " 'pile',\n",
       " '!',\n",
       " '!',\n",
       " 'it',\n",
       " 'was',\n",
       " 'interesting',\n",
       " 'looking',\n",
       " 'back',\n",
       " 'and',\n",
       " 'very',\n",
       " 'sad',\n",
       " ',',\n",
       " 'it',\n",
       " 'makes',\n",
       " 'you',\n",
       " 'realise',\n",
       " 'just',\n",
       " 'how',\n",
       " 'deep',\n",
       " 'the',\n",
       " 'feelings',\n",
       " 'went',\n",
       " 'and',\n",
       " 'although',\n",
       " 'it',\n",
       " 'sounds',\n",
       " 'silly',\n",
       " 'it',\n",
       " '’',\n",
       " 's',\n",
       " 'surprising',\n",
       " 'how',\n",
       " 'quickly',\n",
       " 'those',\n",
       " 'feelings',\n",
       " 'can',\n",
       " 'return',\n",
       " 'over',\n",
       " 'the',\n",
       " 'smallest',\n",
       " 'things',\n",
       " '.',\n",
       " 'anyway',\n",
       " 'having',\n",
       " 'done',\n",
       " 'that',\n",
       " ',',\n",
       " 'it',\n",
       " 'did',\n",
       " 'feel',\n",
       " 'good',\n",
       " 'to',\n",
       " 'box',\n",
       " 'them',\n",
       " 'up',\n",
       " 'and',\n",
       " 'put',\n",
       " 'them',\n",
       " 'away',\n",
       " '.',\n",
       " 'we',\n",
       " 'got',\n",
       " 'taken',\n",
       " 'out',\n",
       " 'for',\n",
       " 'lunch',\n",
       " 'with',\n",
       " 'our',\n",
       " 'ptizer',\n",
       " 'rep',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'nice',\n",
       " 'just',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'usual',\n",
       " '!',\n",
       " 'things',\n",
       " ',',\n",
       " 'drug',\n",
       " 'competition',\n",
       " ',',\n",
       " 'how',\n",
       " 'much',\n",
       " 'we',\n",
       " 'were',\n",
       " 'going',\n",
       " 'to',\n",
       " 'sell',\n",
       " '.',\n",
       " 'thursday',\n",
       " '7th',\n",
       " 'march',\n",
       " 'very',\n",
       " 'busy',\n",
       " 'day',\n",
       " ',',\n",
       " 'everyone',\n",
       " 'has',\n",
       " 'been',\n",
       " 'flat',\n",
       " 'out',\n",
       " 'all',\n",
       " 'day',\n",
       " 'started',\n",
       " 'at',\n",
       " '7am',\n",
       " 'this',\n",
       " 'morning',\n",
       " 'got',\n",
       " 'finished',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'by',\n",
       " '7.30pm',\n",
       " ',',\n",
       " 'very',\n",
       " 'tired',\n",
       " '.',\n",
       " 'hope',\n",
       " 'we',\n",
       " 'get',\n",
       " 'a',\n",
       " 'new',\n",
       " 'vet',\n",
       " 'soon',\n",
       " '!',\n",
       " 'we',\n",
       " 'also',\n",
       " 'had',\n",
       " 'a',\n",
       " 'suspect',\n",
       " 'bse',\n",
       " 'case',\n",
       " 'today',\n",
       " '.',\n",
       " 'informed',\n",
       " 'defra',\n",
       " '.',\n",
       " 'more',\n",
       " 'problems',\n",
       " 'with',\n",
       " 'soa',\n",
       " ',',\n",
       " 'but',\n",
       " 'we',\n",
       " 'got',\n",
       " 'them',\n",
       " 'started',\n",
       " ',',\n",
       " 'one',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'good',\n",
       " 'news',\n",
       " ',',\n",
       " 'i',\n",
       " 'managed',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'new',\n",
       " 'receptionist',\n",
       " 'for',\n",
       " '2',\n",
       " 'days',\n",
       " 'a',\n",
       " 'week',\n",
       " 'so',\n",
       " 'i',\n",
       " 'just',\n",
       " 'need',\n",
       " 'one',\n",
       " 'for',\n",
       " 'the',\n",
       " 'other',\n",
       " '3',\n",
       " '.',\n",
       " 'friday',\n",
       " '8th',\n",
       " 'march',\n",
       " 'quite',\n",
       " 'a',\n",
       " 'good',\n",
       " 'day',\n",
       " 'no',\n",
       " 'major',\n",
       " 'hassles',\n",
       " 'today',\n",
       " ',',\n",
       " 'and',\n",
       " 'still',\n",
       " 'getting',\n",
       " 'busier',\n",
       " '.',\n",
       " 'had',\n",
       " 'a',\n",
       " 'staff',\n",
       " 'meeting',\n",
       " 'to',\n",
       " 'arrange',\n",
       " 'an',\n",
       " 'open',\n",
       " 'day',\n",
       " 'for',\n",
       " 'national',\n",
       " 'pet',\n",
       " 'week',\n",
       " 'in',\n",
       " 'may',\n",
       " ',',\n",
       " 'and',\n",
       " 'sorted',\n",
       " 'out',\n",
       " 'a',\n",
       " 'few',\n",
       " 'other',\n",
       " 'bits',\n",
       " 'and',\n",
       " 'bobs',\n",
       " '.',\n",
       " 'had',\n",
       " 'a',\n",
       " 'good',\n",
       " 'chat',\n",
       " 'with',\n",
       " 'the',\n",
       " 'staff',\n",
       " 'who',\n",
       " 'have',\n",
       " 'all',\n",
       " 'been',\n",
       " 'very',\n",
       " 'busy',\n",
       " 'this',\n",
       " 'week',\n",
       " 'and',\n",
       " 'decided',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'much',\n",
       " 'better',\n",
       " 'to',\n",
       " 'this',\n",
       " 'time',\n",
       " 'last',\n",
       " 'year',\n",
       " ',',\n",
       " 'when',\n",
       " 'we',\n",
       " 'were',\n",
       " 'all',\n",
       " 'very',\n",
       " 'depressed',\n",
       " ',',\n",
       " 'emotionally',\n",
       " 'drained',\n",
       " ',',\n",
       " 'laying',\n",
       " 'off',\n",
       " 'staff',\n",
       " ',',\n",
       " 'uncertain',\n",
       " 'of',\n",
       " 'the',\n",
       " 'future',\n",
       " '.',\n",
       " 'at',\n",
       " 'least',\n",
       " 'now',\n",
       " 'we',\n",
       " 'are',\n",
       " 'doing',\n",
       " 'what',\n",
       " 'we',\n",
       " 'are',\n",
       " 'meant',\n",
       " 'to',\n",
       " 'do',\n",
       " '.',\n",
       " 'saturday',\n",
       " '9th',\n",
       " 'march',\n",
       " 'went',\n",
       " 'shopping',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'with',\n",
       " 'k',\n",
       " ',',\n",
       " 'had',\n",
       " 'a',\n",
       " 'good',\n",
       " 'time',\n",
       " ',',\n",
       " 'even',\n",
       " 'though',\n",
       " 'i',\n",
       " '’',\n",
       " 'm',\n",
       " 'not',\n",
       " 'a',\n",
       " 'good',\n",
       " 'shopper',\n",
       " '.',\n",
       " 'we',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'farmers',\n",
       " '’',\n",
       " 'market',\n",
       " ',',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'heather',\n",
       " 'who',\n",
       " 'works',\n",
       " 'at',\n",
       " 'the',\n",
       " 'auction',\n",
       " 'and',\n",
       " 'she',\n",
       " 'said',\n",
       " 'it',\n",
       " 'had',\n",
       " 'been',\n",
       " 'quite',\n",
       " 'emotional',\n",
       " 'having',\n",
       " 'sales',\n",
       " 'again',\n",
       " 'and',\n",
       " 'the',\n",
       " 'hustle',\n",
       " 'and',\n",
       " 'bustle',\n",
       " ',',\n",
       " 'but',\n",
       " 'they',\n",
       " 'were',\n",
       " 'all',\n",
       " 'happy',\n",
       " 'to',\n",
       " 'see',\n",
       " 'people',\n",
       " 'they',\n",
       " 'hadn',\n",
       " '’',\n",
       " 't',\n",
       " 'seen',\n",
       " 'for',\n",
       " 'sometime',\n",
       " '.',\n",
       " 'met',\n",
       " 'my',\n",
       " 'mum',\n",
       " 'in',\n",
       " 'the',\n",
       " 'afternoon',\n",
       " 'in',\n",
       " 'the',\n",
       " 'snow',\n",
       " 'at',\n",
       " 'killington',\n",
       " 'lake',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'good',\n",
       " 'and',\n",
       " 'the',\n",
       " 'driving',\n",
       " 'was',\n",
       " 'interesting',\n",
       " '.',\n",
       " 'sunday',\n",
       " '10th',\n",
       " 'march',\n",
       " 'mothers',\n",
       " 'day',\n",
       " '–',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " 'and',\n",
       " '[',\n",
       " 'daughter',\n",
       " ']',\n",
       " 'were',\n",
       " 'out',\n",
       " 'for',\n",
       " 'the',\n",
       " 'day',\n",
       " ',',\n",
       " 'so',\n",
       " 'i',\n",
       " 'had',\n",
       " 'a',\n",
       " 'lovely',\n",
       " 'peaceful',\n",
       " 'day',\n",
       " 'doing',\n",
       " 'not',\n",
       " 'a',\n",
       " 'lot',\n",
       " '.',\n",
       " '[',\n",
       " 'daughter',\n",
       " ']',\n",
       " 'got',\n",
       " 'me',\n",
       " 'a',\n",
       " 'funny',\n",
       " 'card',\n",
       " 'and',\n",
       " 'a',\n",
       " 'little',\n",
       " 'hedgehog',\n",
       " 'model',\n",
       " 'for',\n",
       " 'my',\n",
       " 'collection',\n",
       " '.',\n",
       " 'in',\n",
       " 'the',\n",
       " 'evening',\n",
       " 'i',\n",
       " 'collected',\n",
       " 'a',\n",
       " 'vet',\n",
       " 'student',\n",
       " 'from',\n",
       " 'london',\n",
       " 'who',\n",
       " 'is',\n",
       " 'staying',\n",
       " 'with',\n",
       " 'us',\n",
       " 'for',\n",
       " '3',\n",
       " 'weeks',\n",
       " '.',\n",
       " 'so',\n",
       " 'we',\n",
       " 'will',\n",
       " 'have',\n",
       " 'to',\n",
       " 'behave',\n",
       " '.',\n",
       " 'she',\n",
       " 'seems',\n",
       " 'nice',\n",
       " 'and',\n",
       " 'settled',\n",
       " 'into',\n",
       " 'our',\n",
       " 'mad',\n",
       " 'house',\n",
       " 'easily',\n",
       " '.',\n",
       " 'mr',\n",
       " 'w',\n",
       " 'called',\n",
       " 'in',\n",
       " 'to',\n",
       " 'let',\n",
       " 'us',\n",
       " 'know',\n",
       " 'his',\n",
       " 'cows',\n",
       " 'had',\n",
       " 'arrived',\n",
       " 'safely',\n",
       " '.',\n",
       " 'week',\n",
       " 'beginning',\n",
       " '11th',\n",
       " 'march',\n",
       " '02',\n",
       " 'monday',\n",
       " '11th',\n",
       " 'march',\n",
       " 'what',\n",
       " 'a',\n",
       " 'busy',\n",
       " 'day',\n",
       " '.',\n",
       " 'but',\n",
       " 'a',\n",
       " 'total',\n",
       " 'change',\n",
       " 'to',\n",
       " 'this',\n",
       " 'time',\n",
       " 'last',\n",
       " 'year',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'the',\n",
       " 'day',\n",
       " 'our',\n",
       " 'first',\n",
       " 'client',\n",
       " 'was',\n",
       " 'confirmed',\n",
       " 'with',\n",
       " 'f',\n",
       " '&',\n",
       " 'm',\n",
       " '.',\n",
       " 'i',\n",
       " 'helped',\n",
       " '[',\n",
       " 'another',\n",
       " 'vet',\n",
       " ']',\n",
       " 'do',\n",
       " 'a',\n",
       " 'caesarean',\n",
       " 'on',\n",
       " 'a',\n",
       " 'cow',\n",
       " ',',\n",
       " 'that',\n",
       " 'was',\n",
       " 'fun',\n",
       " ',',\n",
       " 'they',\n",
       " 'are',\n",
       " 'farmers',\n",
       " 'that',\n",
       " 'have',\n",
       " 'moved',\n",
       " 'farm',\n",
       " 'and',\n",
       " 'restocked',\n",
       " '–',\n",
       " 'very',\n",
       " 'positive',\n",
       " '.',\n",
       " 'one',\n",
       " 'of',\n",
       " 'our',\n",
       " 'new',\n",
       " 'receptionists',\n",
       " 'started',\n",
       " 'but',\n",
       " 'i',\n",
       " 'didn',\n",
       " '’',\n",
       " 't',\n",
       " 'get',\n",
       " 'much',\n",
       " 'chance',\n",
       " 'to',\n",
       " 'see',\n",
       " 'her',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'caesar',\n",
       " '.',\n",
       " 'barbara',\n",
       " 'looked',\n",
       " 'after',\n",
       " 'her',\n",
       " 'well',\n",
       " 'and',\n",
       " 'she',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'enjoy',\n",
       " 'it',\n",
       " '.',\n",
       " 'there',\n",
       " 'were',\n",
       " 'lots',\n",
       " 'of',\n",
       " 'calls',\n",
       " 'in',\n",
       " 'just',\n",
       " 'like',\n",
       " 'the',\n",
       " 'old',\n",
       " 'days',\n",
       " 'but',\n",
       " 'we',\n",
       " 'really',\n",
       " 'need',\n",
       " 'another',\n",
       " 'vet',\n",
       " ',',\n",
       " 'the',\n",
       " 'adverts',\n",
       " 'in',\n",
       " 'on',\n",
       " 'thursday',\n",
       " 'so',\n",
       " 'fingers',\n",
       " 'crossed',\n",
       " '.',\n",
       " 'tuesday',\n",
       " 'another',\n",
       " 'busy',\n",
       " 'day',\n",
       " 'and',\n",
       " 'another',\n",
       " 'caesar',\n",
       " ',',\n",
       " 'the',\n",
       " 'calf',\n",
       " 'was',\n",
       " 'dead',\n",
       " 'unfortunately',\n",
       " '.',\n",
       " 'the',\n",
       " 'cow',\n",
       " 'with',\n",
       " 'query',\n",
       " 'bse',\n",
       " 'was',\n",
       " 'taken',\n",
       " 'away',\n",
       " 'for',\n",
       " 'tests',\n",
       " ',',\n",
       " 'which',\n",
       " 'was',\n",
       " 'sad',\n",
       " '.',\n",
       " 'my',\n",
       " 'highlight',\n",
       " 'of',\n",
       " 'my',\n",
       " 'day',\n",
       " 'was',\n",
       " 'the',\n",
       " 'farm',\n",
       " 'across',\n",
       " 'from',\n",
       " 'us',\n",
       " 'turned',\n",
       " 'some',\n",
       " 'of',\n",
       " 'his',\n",
       " 'cows',\n",
       " 'out',\n",
       " 'again',\n",
       " '.',\n",
       " 'i',\n",
       " 'call',\n",
       " 'it',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'window',\n",
       " 'view',\n",
       " ',',\n",
       " 'normally',\n",
       " 'i',\n",
       " 'can',\n",
       " 'see',\n",
       " 'sheep',\n",
       " 'in',\n",
       " 'the',\n",
       " 'fields',\n",
       " 'at',\n",
       " 'the',\n",
       " 'back',\n",
       " 'and',\n",
       " 'the',\n",
       " 'cows',\n",
       " 'across',\n",
       " 'the',\n",
       " 'road',\n",
       " ',',\n",
       " 'the',\n",
       " 'sheep',\n",
       " 'came',\n",
       " 'back',\n",
       " 'a',\n",
       " 'couple',\n",
       " 'of',\n",
       " 'months',\n",
       " 'ago',\n",
       " 'and',\n",
       " 'the',\n",
       " 'cows',\n",
       " 'but',\n",
       " 'i',\n",
       " 'haven',\n",
       " '’',\n",
       " 't',\n",
       " 'actually',\n",
       " 'been',\n",
       " 'able',\n",
       " 'to',\n",
       " 'see',\n",
       " 'them',\n",
       " ',',\n",
       " 'so',\n",
       " 'it',\n",
       " 'was',\n",
       " 'very',\n",
       " 'special',\n",
       " '.',\n",
       " 'never',\n",
       " 'really',\n",
       " 'stopped',\n",
       " 'today',\n",
       " 'and',\n",
       " 'we',\n",
       " 'did',\n",
       " 'dog',\n",
       " 'training',\n",
       " 'classes',\n",
       " 'at',\n",
       " 'night',\n",
       " ',',\n",
       " 'so',\n",
       " 'i',\n",
       " 'collected',\n",
       " '[',\n",
       " 'daughter',\n",
       " ']',\n",
       " 'from',\n",
       " 'her',\n",
       " 'yfc',\n",
       " 'meeting',\n",
       " 'and',\n",
       " 'got',\n",
       " 'fish',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foot_mouth_df.loc[2,'txt_lower'] #Just to make sure it is converting ALL the caps by inspecting one of the file texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay that worked!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spelling correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________\n",
    "Everybody loves spelling... RIGHT?!?\n",
    "\n",
    "Fortunately, there are several decent spellchecking packages written for python. They are not automatically installed and ready to import in the same way that the 'os' or 'nltk' packages were, but we just need to install the packages and import the functions we need through an installer called 'pip'. You will see 'pip' in the next code block, but since this is in jupyter notebook rather than directly in a python shell, we need to put a '!' in front of the 'pip' function. Don't worry too much about that now, I just mention  it here in case you find it interesting to know. \n",
    "\n",
    "The next code cell:\n",
    "- installs the 'autocorrect' package,\n",
    "- imports the Speller function, and\n",
    "- creates a one-word command that specifies that the Speller function should use English language. \n",
    "\n",
    "Run/Shift+Enter, as per usual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autocorrect in c:\\users\\l_pel\\anaconda3\\envs\\q-steps_projects\\lib\\site-packages (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install autocorrect\n",
    "from autocorrect import Speller\n",
    "spell = Speller(lang='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________\n",
    "Super. Creating that one-word command saves us some time, which is maybe less important here but is a good skill to be aware of if you are working on text-mining every day for weeks on end. Always be on the look out for good ways to save time. \n",
    "\n",
    "Moving on, we need to iterate over our corpus, checking and correcting each token. This is easy to do if you start with a new, empty list (I called mine 'corpus_correct_spell'). As I work through corpus_words, one token at a time, we append (which is just fancy for 'add to the end') the corrected word to our new blank list. \n",
    "\n",
    "Then, as usual, we have a quick look at the first 100 entries in the new 'corpus_correct_spell'. \n",
    "\n",
    "Run/Shift+Enter. You know how to do it. Don't worry if it takes a while... Checking the spelling on each word is not a cakewalk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information\n",
      "about\n",
      "diarist\n",
      "date\n",
      "of\n",
      "birth\n",
      ":\n",
      "1975\n",
      "gender\n",
      ":\n",
      "m\n",
      "occupation\n",
      ":\n",
      "group\n",
      "6\n",
      "geographic\n",
      "region\n",
      ":\n",
      "north\n",
      "cambria\n",
      "diary\n",
      "1\n",
      "thursday\n",
      "meeting\n",
      "@\n",
      "n\n",
      "lakes\n",
      "friday\n",
      "tb\n",
      "testing\n",
      "on\n",
      "restoring\n",
      "farm\n",
      ".\n",
      "usual\n",
      "chat\n",
      "and\n",
      "defra\n",
      "comments\n",
      "the\n",
      "meeting\n",
      "(\n",
      "research\n",
      "panel\n",
      "gp\n",
      "6\n",
      ")\n",
      "at\n",
      "the\n",
      "north\n",
      "lakes\n",
      "was\n",
      "interesting\n",
      ".\n",
      "it\n",
      "surprises\n",
      "me\n",
      "sometimes\n",
      "how\n",
      "people\n",
      "(\n",
      "myself\n",
      "included\n",
      ")\n",
      "never\n",
      "seem\n",
      "to\n",
      "tire\n",
      "of\n",
      "the\n",
      "same\n",
      "stories\n",
      "and\n",
      "complaints\n",
      "over\n",
      "how\n",
      "the\n",
      "crisis\n",
      "was\n",
      "handled\n",
      ".\n",
      "some\n",
      "of\n",
      "the\n",
      "episodes\n",
      "recounted\n",
      "must\n",
      "have\n",
      "been\n",
      "told\n",
      "dozens\n",
      "of\n",
      "times\n",
      "over\n",
      "the\n",
      "last\n",
      "year\n",
      "but\n",
      "whoever\n",
      "says\n",
      "it\n",
      "always\n",
      "seems\n",
      "just\n",
      "as\n",
      "keen\n",
      "to\n",
      "say\n",
      "it\n",
      "again\n",
      "–\n",
      "perhaps\n",
      "a\n",
      "reflection\n",
      "of\n",
      "how\n",
      "deeply\n",
      "people\n",
      "feel\n",
      "about\n",
      "the\n",
      "events\n",
      "of\n",
      "the\n",
      "last\n",
      "year\n",
      ".\n",
      "having\n",
      "said\n",
      "that\n",
      ",\n",
      "most\n",
      "of\n",
      "the\n",
      "resentment\n",
      "and\n",
      "rants\n",
      "that\n",
      "i\n",
      "hear\n",
      "on\n",
      "daily\n",
      "farm\n",
      "visits\n",
      "are\n",
      "focused\n",
      "fairly\n",
      "and\n",
      "squarely\n",
      "at\n",
      "defra\n",
      "and\n",
      "not\n",
      "ffd\n",
      "virus\n",
      ".\n",
      "farmers\n",
      "seem\n",
      "far\n",
      "more\n",
      "upset\n",
      "at\n",
      "the\n",
      "construction\n",
      "put\n",
      "on\n",
      "them\n",
      "by\n",
      "defra\n",
      "than\n",
      "they\n",
      "do\n",
      "by\n",
      "the\n",
      "loss\n",
      "of\n",
      "stock\n",
      "now\n",
      ",\n",
      "although\n",
      "i\n",
      "know\n",
      "and\n",
      "saw\n",
      "how\n",
      "utterly\n",
      "devastated\n",
      "most\n",
      "were\n",
      "when\n",
      "they\n",
      "were\n",
      "actually\n",
      "diagnosed\n",
      "with\n",
      "the\n",
      "virus\n",
      "and\n",
      "in\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "# Let's first spell check the first 100 words in the first row...\n",
    "tokenised = [] \n",
    "\n",
    "for i in foot_mouth_df['spell_checked'][0][:200]:\n",
    "    print(i)\n",
    "    tokenised.append(spell(i))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['information', 'about', 'diarist', 'date', 'of', 'birth', ':', '1975', 'gender', ':', 'm', 'occupation', ':', 'group', '6', 'geographic', 'region', ':', 'north', 'cambria', 'diary', '1', 'thursday', 'meeting', '@', 'n', 'lakes', 'friday', 'tb', 'testing', 'on', 'restoring', 'farm', '.', 'usual', 'chat', 'and', 'der', 'comments', 'the', 'meeting', '(', 'research', 'panel', 'gp', '6', ')', 'at', 'the', 'north', 'lakes', 'was', 'interesting', '.', 'it', 'surprises', 'me', 'sometimes', 'how', 'people', '(', 'myself', 'included', ')', 'never', 'seem', 'to', 'tire', 'of', 'the', 'same', 'stories', 'and', 'complaints', 'over', 'how', 'the', 'crisis', 'was', 'handled', '.', 'some', 'of', 'the', 'episodes', 'recounted', 'must', 'have', 'been', 'told', 'dozens', 'of', 'times', 'over', 'the', 'last', 'year', 'but', 'whoever', 'says']\n"
     ]
    }
   ],
   "source": [
    "print(tokenised)\n",
    "\n",
    "# We can see that it's worked because defra has been changed to 'der'...an example of how spell check can be troublesome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(foot_mouth_df['txt_lower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To solve this, I adapted Julia's code above which she used to lowercase each token in each list...\n",
    "\n",
    "# foot_mouth_df['txt_lower'] = foot_mouth_df['tokenised_words'].apply(lambda x: [w.lower() for w in x])\n",
    "\n",
    "# You were on the right lines with list comprehension!\n",
    "\n",
    "foot_mouth_df['spell_checked'] = foot_mouth_df['txt_lower'].apply(lambda x: [spell(w) for w in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So...why didn't your code here work:\n",
    "\n",
    "> `foot_mouth_df['Correct_spelling'] = [' '.join([spell(i) for i in pd.Series.str.split(x)]) for x infoot_mouth_df['txt_lower']]`\n",
    "\n",
    "You have referenced pd.Series.str.split(x), but this method can only be used on a pandas series\n",
    "\n",
    "You are asking Python to apply str.split to nothing, because pd.Series is not a series\n",
    "\n",
    "This is why you received the AttributeError 'str' object has no attribute `_inferred_dtype` - shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.str.split('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I also think join might not have been the right method to use because it would have meant our words in the list are no longer tokenised\n",
    "# Therefore, we wouldn't be able to iterate over the words in each list\n",
    "\n",
    "[' '.join(foot_mouth_df['spell_checked'][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>tokenised_words</th>\n",
       "      <th>txt_lower</th>\n",
       "      <th>spell_checked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5407diary02.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5407diary03.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1966...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5407diary07.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5407diary08.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1963...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5407diary09.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1981...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number         Filename                                    everything_else  \\\n",
       "0       0  5407diary02.rtf  \\n\\nInformation about diarist\\nDate of birth: ...   \n",
       "1       1  5407diary03.rtf  Information about diarist\\nDate of birth: 1966...   \n",
       "2       2  5407diary07.rtf  \\n\\nInformation about diarist\\nDate of birth: ...   \n",
       "3       3  5407diary08.rtf  Information about diarist\\nDate of birth: 1963...   \n",
       "4       4  5407diary09.rtf  Information about diarist\\nDate of birth: 1981...   \n",
       "\n",
       "                                     tokenised_words  \\\n",
       "0  [Information, about, diarist, Date, of, birth,...   \n",
       "1  [Information, about, diarist, Date, of, birth,...   \n",
       "2  [Information, about, diarist, Date, of, birth,...   \n",
       "3  [Information, about, diarist, Date, of, birth,...   \n",
       "4  [Information, about, diarist, Date, of, birth,...   \n",
       "\n",
       "                                           txt_lower  \\\n",
       "0  [information, about, diarist, date, of, birth,...   \n",
       "1  [information, about, diarist, date, of, birth,...   \n",
       "2  [information, about, diarist, date, of, birth,...   \n",
       "3  [information, about, diarist, date, of, birth,...   \n",
       "4  [information, about, diarist, date, of, birth,...   \n",
       "\n",
       "                                       spell_checked  \n",
       "0  [information, about, diarist, date, of, birth,...  \n",
       "1  [information, about, diarist, date, of, birth,...  \n",
       "2  [information, about, diarist, date, of, birth,...  \n",
       "3  [information, about, diarist, date, of, birth,...  \n",
       "4  [information, about, diarist, date, of, birth,...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check that the column creation worked...\n",
    "\n",
    "foot_mouth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Let's check that spell check has actually worked...\n",
    "# We can look for the word 'defra' to see if it's been changed to 'der'\n",
    "\n",
    "\n",
    "if 'der' in foot_mouth_df['spell_checked'][0][:100]:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [' '.join([spell(i) for i in x.split(foot_mouth_df['txt_lower'],\",\")for x in foot_mouth_df['txt_lower']])]  \n",
    "\n",
    "#foot_mouth_df['correct_spell'] = [' '.join([spell(i) for i in x.split()]) for x in foot_mouth_df['correct_spell']]\n",
    "\n",
    "\n",
    "#for row in foot_mouth_df['correct_spell']:\n",
    "#    foot_mouth_df['correct_spell'].append(check(row))\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "#foot_mouth_df['correct_spell'] = [' '.join([check(word) for word in row.split()]) for row in foot_mouth_df['txt_lower']]\n",
    "\n",
    "#[' '.join([spell(i) for i in x.split()]) for x in df['colTest']]\n",
    "\n",
    "#foot_mouth_df['txt_lower'] = foot_mouth_df['tokenised_words'].apply(lambda x: check(x) for x in foot_mouth_df['tokenised_words'])\n",
    "\n",
    "\n",
    "#.apply(lambda x: [check(w) for w in x])\n",
    "\n",
    "#for word in corpus_words:\n",
    "#    corpus_correct_spell.append(check(word))    \n",
    "\n",
    "#print(corpus_correct_spell[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________\n",
    "How did it do? Well, this spell-checker replaced 'haz' with 'had' rather than 'has'. That is ok, I guess. No automatic spelling correction programme will get it 100% right 100% of the time. Maybe your project has specific research questions that won't work with this decision. \n",
    "\n",
    "In that case, you would have to check out some other spell-checkers like textblob or pyspellchecker. You might even want to custom build or adapt your own spell-checker, especially if you were working with very non-standard text, like comment boards that use a bunch of slang, common typos, or specific terms. \n",
    "\n",
    "But take a moment here and consider the following questions... \n",
    "- Can you apply this spell-checker to corpus_sentences rather than corpus_words? If you are not sure what happens, try it out by copying, editing and re-running the above code block. \n",
    "- Should you have appled this spell-checker to corpus_lower rather than corpus_words? What difference would it make? Again, try it out if you are not sure. \n",
    "\n",
    "Next up, specific replacements with RegEx! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_corpus_correct_spell = []\n",
    "for sent in corpus_sentences:\n",
    "    sent_corpus_correct_spell.append(check(sent))    \n",
    "\n",
    "print(sent_corpus_correct_spell[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leila to do if wants a challenge:\n",
    "\n",
    "How about replacing the word \"der\" with \"defra\" for the first row in the 'spell_checked\" column?\n",
    "Then, if you've done this with the first row, how about for the first five rows...or the whole dataset?\n",
    "Can you do this without any issues i.e., can you match the whole word 'der' and change it to 'defra' WITHOUT changing other words like 'gender' to 'gendefra'??\n",
    "\n",
    "If you get stuck, let me know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacement_mapping(x):\n",
    "        if x == \"der\":\n",
    "            return re.sub(\"der\",\"defra\",x)\n",
    "        else:\n",
    "            return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defra\n",
      "gender\n"
     ]
    }
   ],
   "source": [
    "test = \"der\"\n",
    "test = replacement_mapping(test)\n",
    "print(test)\n",
    "\n",
    "test_2 = \"gender\"\n",
    "\n",
    "test_3 = replacement_mapping(test_2)\n",
    "print(test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_mouth_df[\"spell_checked\"] = foot_mouth_df[\"spell_checked\"].apply(lambda x:[replacement_mapping(w) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['information',\n",
       " 'about',\n",
       " 'diarist',\n",
       " 'date',\n",
       " 'of',\n",
       " 'birth',\n",
       " ':',\n",
       " '1957',\n",
       " 'gender',\n",
       " ':',\n",
       " 'f',\n",
       " 'occupation',\n",
       " ':',\n",
       " 'group',\n",
       " '1',\n",
       " 'geographic',\n",
       " 'region',\n",
       " ':',\n",
       " 'north',\n",
       " 'cambria',\n",
       " 'week',\n",
       " '1',\n",
       " ',',\n",
       " '24/12/01',\n",
       " 'monday',\n",
       " '–',\n",
       " 'took',\n",
       " '[',\n",
       " 'son',\n",
       " '&',\n",
       " 'daughter',\n",
       " ']',\n",
       " 'down',\n",
       " 'town',\n",
       " 'so',\n",
       " 'they',\n",
       " 'could',\n",
       " 'do',\n",
       " 'there',\n",
       " 'christmas',\n",
       " 'shopping',\n",
       " '.',\n",
       " 'i',\n",
       " 'went',\n",
       " 'to',\n",
       " 'morrison',\n",
       " 'to',\n",
       " 'do',\n",
       " 'some',\n",
       " 'food',\n",
       " 'shopping',\n",
       " ',',\n",
       " 'went',\n",
       " 'to',\n",
       " 'see',\n",
       " 'my',\n",
       " 'mam',\n",
       " ',',\n",
       " 'then',\n",
       " 'went',\n",
       " 'to',\n",
       " 'pick',\n",
       " '[',\n",
       " 'son',\n",
       " '&',\n",
       " 'daughter',\n",
       " ']',\n",
       " 'up',\n",
       " '.',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'pub',\n",
       " '.',\n",
       " 'i',\n",
       " 'tidy',\n",
       " 'up',\n",
       " 'so',\n",
       " 'i',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'have',\n",
       " 'to',\n",
       " 'do',\n",
       " 'it',\n",
       " 'tomorrow',\n",
       " '.',\n",
       " 'bed',\n",
       " 'about',\n",
       " '1am',\n",
       " '.',\n",
       " 'tuesday',\n",
       " '.',\n",
       " 'christmas',\n",
       " 'day',\n",
       " '.',\n",
       " 'kids',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'wake',\n",
       " 'us',\n",
       " 'up',\n",
       " 'in',\n",
       " 'the',\n",
       " 'morning',\n",
       " 'any',\n",
       " 'more',\n",
       " ',',\n",
       " 'they',\n",
       " 'are',\n",
       " 'older',\n",
       " 'now',\n",
       " '.',\n",
       " '[',\n",
       " 'daughter',\n",
       " ']',\n",
       " 'still',\n",
       " 'gets',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'excited',\n",
       " 'about',\n",
       " 'christmas',\n",
       " '.',\n",
       " 'she',\n",
       " 'got',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'sports',\n",
       " 'clothes',\n",
       " '+',\n",
       " 'a',\n",
       " 't.',\n",
       " 'bar',\n",
       " 'chain',\n",
       " ',',\n",
       " '+',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'more',\n",
       " '.',\n",
       " 'i',\n",
       " 'got',\n",
       " 'a',\n",
       " 'bread',\n",
       " 'maker',\n",
       " ',',\n",
       " 'sports',\n",
       " 'clothes',\n",
       " '+',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'money',\n",
       " '.',\n",
       " 'got',\n",
       " 'christmas',\n",
       " 'dinner',\n",
       " 'ready',\n",
       " '.',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " '&',\n",
       " '[',\n",
       " 'daughter',\n",
       " ']',\n",
       " 'went',\n",
       " 'for',\n",
       " 'my',\n",
       " 'mam',\n",
       " '&',\n",
       " 'dad',\n",
       " ',',\n",
       " 'they',\n",
       " 'come',\n",
       " 'for',\n",
       " 'their',\n",
       " 'dinner',\n",
       " 'because',\n",
       " 'we',\n",
       " 'are',\n",
       " 'all',\n",
       " 'grown',\n",
       " 'up',\n",
       " '.',\n",
       " 'had',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'dinner',\n",
       " '.',\n",
       " 'watch',\n",
       " 'tv',\n",
       " 'and',\n",
       " 'opened',\n",
       " 'some',\n",
       " 'more',\n",
       " 'presents',\n",
       " '.',\n",
       " '[',\n",
       " 'daughter',\n",
       " ']',\n",
       " '+',\n",
       " 'took',\n",
       " 'mam',\n",
       " 'and',\n",
       " 'dad',\n",
       " 'home',\n",
       " ',',\n",
       " 'stayed',\n",
       " 'for',\n",
       " 'tea',\n",
       " ',',\n",
       " 'my',\n",
       " 'brothers',\n",
       " '+',\n",
       " 'sister',\n",
       " 'and',\n",
       " 'their',\n",
       " 'families',\n",
       " 'came',\n",
       " 'as',\n",
       " 'well',\n",
       " '.',\n",
       " 'had',\n",
       " 'a',\n",
       " 'good',\n",
       " 'night',\n",
       " '.',\n",
       " 'wednesday',\n",
       " '.',\n",
       " 'had',\n",
       " 'a',\n",
       " 'quite',\n",
       " 'day',\n",
       " 'went',\n",
       " 'to',\n",
       " 'see',\n",
       " '[',\n",
       " 'sister',\n",
       " ']',\n",
       " 'to',\n",
       " 'see',\n",
       " 'what',\n",
       " 'my',\n",
       " 'nephew',\n",
       " '&',\n",
       " 'niece',\n",
       " 'got',\n",
       " 'for',\n",
       " 'christmas',\n",
       " ',',\n",
       " 'they',\n",
       " 'were',\n",
       " 'so',\n",
       " 'excited',\n",
       " 'telling',\n",
       " 'me',\n",
       " 'what',\n",
       " 'they',\n",
       " 'got',\n",
       " '.',\n",
       " 'home',\n",
       " ',',\n",
       " 'watch',\n",
       " '.',\n",
       " 'tv',\n",
       " '.',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'pub',\n",
       " ',',\n",
       " 'but',\n",
       " 'it',\n",
       " 'was',\n",
       " 'closed',\n",
       " 'he',\n",
       " 'wasn',\n",
       " '’',\n",
       " 't',\n",
       " 'very',\n",
       " 'happy',\n",
       " 'he',\n",
       " 'had',\n",
       " 'to',\n",
       " 'walk',\n",
       " 'all',\n",
       " 'the',\n",
       " 'way',\n",
       " 'home',\n",
       " 'in',\n",
       " 'the',\n",
       " 'rain',\n",
       " '.',\n",
       " 'thursday',\n",
       " '.',\n",
       " 'went',\n",
       " 'down',\n",
       " 'town',\n",
       " '.',\n",
       " 'got',\n",
       " 'my',\n",
       " 'god-daughter',\n",
       " 'a',\n",
       " '21st',\n",
       " 'present',\n",
       " ',',\n",
       " 'a',\n",
       " 'little',\n",
       " 'teddy',\n",
       " 'with',\n",
       " 'a',\n",
       " '21s',\n",
       " 'key',\n",
       " 'on',\n",
       " 'it',\n",
       " '.',\n",
       " 'put',\n",
       " 'some',\n",
       " 'money',\n",
       " 'in',\n",
       " 'her',\n",
       " 'card',\n",
       " '.',\n",
       " 'gave',\n",
       " 'it',\n",
       " 'to',\n",
       " 'her',\n",
       " 'dad',\n",
       " '.',\n",
       " 'took',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " 'and',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'domino',\n",
       " 'team',\n",
       " 'to',\n",
       " 'the',\n",
       " 'pub',\n",
       " 'in',\n",
       " 'the',\n",
       " 'next',\n",
       " 'village',\n",
       " '.',\n",
       " 'i',\n",
       " 'went',\n",
       " 'home',\n",
       " '.',\n",
       " 'watch',\n",
       " 't.v',\n",
       " '.',\n",
       " 'went',\n",
       " 'back',\n",
       " 'for',\n",
       " 'them',\n",
       " 'at',\n",
       " '12.30am',\n",
       " '.',\n",
       " 'had',\n",
       " 'to',\n",
       " 'go',\n",
       " 'in',\n",
       " 'the',\n",
       " 'pub',\n",
       " 'for',\n",
       " 'them',\n",
       " ',',\n",
       " 'the',\n",
       " 'were',\n",
       " 'all',\n",
       " 'having',\n",
       " 'a',\n",
       " 'laugh',\n",
       " 'and',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'have',\n",
       " 'had',\n",
       " 'a',\n",
       " 'good',\n",
       " 'night',\n",
       " '.',\n",
       " 'dropped',\n",
       " 'everyone',\n",
       " 'at',\n",
       " 'their',\n",
       " 'home',\n",
       " '.',\n",
       " 'friday',\n",
       " '.',\n",
       " '[',\n",
       " 'daughter',\n",
       " ']',\n",
       " '+',\n",
       " 'i',\n",
       " 'went',\n",
       " 'down',\n",
       " 'town',\n",
       " ',',\n",
       " 'we',\n",
       " 'were',\n",
       " 'in',\n",
       " 'every',\n",
       " 'sport',\n",
       " 'shop',\n",
       " 'in',\n",
       " 'town',\n",
       " ',',\n",
       " 'she',\n",
       " 'got',\n",
       " 'astro',\n",
       " 'trainers',\n",
       " '.',\n",
       " 'home',\n",
       " 'about',\n",
       " '4pm',\n",
       " '.',\n",
       " 'saturday',\n",
       " '.',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " '&',\n",
       " 'i',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'pub',\n",
       " '.',\n",
       " 'l',\n",
       " '+',\n",
       " 'p',\n",
       " ',',\n",
       " 'j',\n",
       " ',',\n",
       " 'and',\n",
       " 'his',\n",
       " 'son',\n",
       " 'were',\n",
       " 'in',\n",
       " 'but',\n",
       " 'no',\n",
       " 'm',\n",
       " 'they',\n",
       " 'had',\n",
       " 'an',\n",
       " 'argument',\n",
       " '.',\n",
       " 'so',\n",
       " 'they',\n",
       " 'had',\n",
       " 'come',\n",
       " 'out',\n",
       " 'for',\n",
       " 'peace',\n",
       " '&',\n",
       " 'quite',\n",
       " '.',\n",
       " 'it',\n",
       " 'was',\n",
       " 'very',\n",
       " 'cold',\n",
       " 'in',\n",
       " 'the',\n",
       " 'pub',\n",
       " ',',\n",
       " 'went',\n",
       " 'and',\n",
       " 'stood',\n",
       " 'in',\n",
       " 'front',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fire',\n",
       " '.',\n",
       " 'we',\n",
       " 'were',\n",
       " 'thinking',\n",
       " 'of',\n",
       " 'going',\n",
       " 'to',\n",
       " 'the',\n",
       " 'next',\n",
       " 'pub',\n",
       " ',',\n",
       " 'but',\n",
       " 'it',\n",
       " 'was',\n",
       " 'getting',\n",
       " 'to',\n",
       " 'late',\n",
       " '.',\n",
       " 'home',\n",
       " 'about',\n",
       " '12.30',\n",
       " '.',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " 'would',\n",
       " 'stay',\n",
       " 'longer',\n",
       " 'but',\n",
       " 'he',\n",
       " 'can',\n",
       " 'never',\n",
       " 'get',\n",
       " 'up',\n",
       " 'in',\n",
       " 'the',\n",
       " 'morning',\n",
       " '.',\n",
       " 'sunday',\n",
       " '.',\n",
       " 'i',\n",
       " 'just',\n",
       " 'done',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'house',\n",
       " 'work',\n",
       " '.',\n",
       " 'week',\n",
       " '2',\n",
       " 'monday',\n",
       " 'was',\n",
       " 'our',\n",
       " 'last',\n",
       " 'day',\n",
       " ',',\n",
       " 'our',\n",
       " '28th',\n",
       " 'day',\n",
       " 'of',\n",
       " 'having',\n",
       " 'our',\n",
       " 'cows',\n",
       " 'on',\n",
       " 'the',\n",
       " 'farm',\n",
       " ',',\n",
       " 'the',\n",
       " 'vet',\n",
       " 'came',\n",
       " 'to',\n",
       " 'check',\n",
       " 'them',\n",
       " 'over',\n",
       " 'and',\n",
       " 'as',\n",
       " 'far',\n",
       " 'as',\n",
       " 'he',\n",
       " 'is',\n",
       " 'concerned',\n",
       " 'everything',\n",
       " 'was',\n",
       " 'o.k',\n",
       " '.',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " 'was',\n",
       " 'pleased',\n",
       " 'he',\n",
       " 'didn',\n",
       " '’',\n",
       " 't',\n",
       " 'have',\n",
       " 'anything',\n",
       " 'to',\n",
       " 'worry',\n",
       " 'about',\n",
       " 'for',\n",
       " 'the',\n",
       " 'new',\n",
       " 'year',\n",
       " ',',\n",
       " 'he',\n",
       " 'could',\n",
       " 'have',\n",
       " 'a',\n",
       " 'good',\n",
       " 'night',\n",
       " 'and',\n",
       " 'get',\n",
       " 'lots',\n",
       " 'to',\n",
       " 'drink',\n",
       " '.',\n",
       " 'i',\n",
       " 'got',\n",
       " 'everything',\n",
       " 'ready',\n",
       " 'for',\n",
       " 'the',\n",
       " 'buffet',\n",
       " '.',\n",
       " 'we',\n",
       " 'were',\n",
       " 'late',\n",
       " 'to',\n",
       " 'go',\n",
       " 'out',\n",
       " ',',\n",
       " 'went',\n",
       " 'to',\n",
       " 'burgh',\n",
       " '1st',\n",
       " '.',\n",
       " 'had',\n",
       " 'a',\n",
       " 'good',\n",
       " 'chatter',\n",
       " 'with',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ladies',\n",
       " ',',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " 'had',\n",
       " 'a',\n",
       " 'few',\n",
       " 'games',\n",
       " 'of',\n",
       " 'nominees',\n",
       " '.',\n",
       " 'the',\n",
       " 'pub',\n",
       " 'was',\n",
       " 'rather',\n",
       " 'quiet',\n",
       " '.',\n",
       " 'went',\n",
       " 'to',\n",
       " 'monkhill',\n",
       " ',',\n",
       " 'when',\n",
       " 'we',\n",
       " 'walk',\n",
       " 'through',\n",
       " 'the',\n",
       " 'door',\n",
       " 'they',\n",
       " 'all',\n",
       " 'cheered',\n",
       " '.',\n",
       " 'it',\n",
       " 'was',\n",
       " 'rather',\n",
       " 'quiet',\n",
       " ',',\n",
       " 'especially',\n",
       " 'for',\n",
       " 'new',\n",
       " 'years',\n",
       " 'eve',\n",
       " '.',\n",
       " 'there',\n",
       " 'was',\n",
       " 'about',\n",
       " 'a',\n",
       " 'dozen',\n",
       " 'kids',\n",
       " 'in',\n",
       " 'the',\n",
       " 'pub',\n",
       " 'all',\n",
       " 'drinking',\n",
       " 'alcohol',\n",
       " '.',\n",
       " 'i',\n",
       " 'think',\n",
       " 'it',\n",
       " '’',\n",
       " 's',\n",
       " 'bad',\n",
       " 'for',\n",
       " 'kids',\n",
       " 'to',\n",
       " 'be',\n",
       " 'drinking',\n",
       " 'in',\n",
       " 'a',\n",
       " 'public',\n",
       " 'house',\n",
       " '.',\n",
       " 'they',\n",
       " 'were',\n",
       " 'being',\n",
       " 'sick',\n",
       " 'and',\n",
       " 'misbehavior',\n",
       " ',',\n",
       " 'it',\n",
       " 'just',\n",
       " 'spoiled',\n",
       " 'the',\n",
       " 'night',\n",
       " '.',\n",
       " 'about',\n",
       " 'half',\n",
       " '1',\n",
       " '–',\n",
       " '2am',\n",
       " 'we',\n",
       " 'went',\n",
       " 'home',\n",
       " 'with',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'friend',\n",
       " 'following',\n",
       " '.',\n",
       " 'i',\n",
       " 'fed',\n",
       " 'them',\n",
       " 'all',\n",
       " 'and',\n",
       " 'gave',\n",
       " 'more',\n",
       " 'drink',\n",
       " 'had',\n",
       " 'a',\n",
       " 'good',\n",
       " 'talking',\n",
       " 'session',\n",
       " '.',\n",
       " 'i',\n",
       " 'was',\n",
       " 'the',\n",
       " 'taxi',\n",
       " 'to',\n",
       " 'people',\n",
       " '’',\n",
       " 's',\n",
       " 'home',\n",
       " '.',\n",
       " 'the',\n",
       " 'last',\n",
       " '2',\n",
       " 'were',\n",
       " 'about',\n",
       " 'half',\n",
       " '4',\n",
       " 'new',\n",
       " 'years',\n",
       " 'day',\n",
       " '.',\n",
       " 'tuesday',\n",
       " '.',\n",
       " 'done',\n",
       " 'nothing',\n",
       " 'exciting',\n",
       " '.',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " 'fell',\n",
       " 'asleep',\n",
       " '.',\n",
       " 'i',\n",
       " 'went',\n",
       " 'to',\n",
       " 'see',\n",
       " 'my',\n",
       " 'mother',\n",
       " 'in-law',\n",
       " '.',\n",
       " 'stay',\n",
       " 'in',\n",
       " '.',\n",
       " 'wednesday',\n",
       " '.',\n",
       " 'went',\n",
       " 'to',\n",
       " 'town',\n",
       " 'to',\n",
       " 'take',\n",
       " '[',\n",
       " 'daughter',\n",
       " ']',\n",
       " '’',\n",
       " 's',\n",
       " 'lamp',\n",
       " 'back',\n",
       " 'her',\n",
       " 'brother',\n",
       " 'bought',\n",
       " 'her',\n",
       " 'for',\n",
       " 'christmas',\n",
       " ',',\n",
       " 'went',\n",
       " 'and',\n",
       " 'looked',\n",
       " 'at',\n",
       " 'some',\n",
       " 'hoover',\n",
       " 'settles',\n",
       " ',',\n",
       " 'microwave',\n",
       " ',',\n",
       " 'home',\n",
       " 'about',\n",
       " '4pm',\n",
       " '.',\n",
       " 'got',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " 'his',\n",
       " 'tea',\n",
       " ',',\n",
       " 'stayed',\n",
       " 'in',\n",
       " 'watch',\n",
       " 't.v',\n",
       " '.',\n",
       " 'thursday',\n",
       " '.',\n",
       " 'had',\n",
       " 'an',\n",
       " 'afternoon',\n",
       " 'of',\n",
       " 'repairing',\n",
       " 'jeans',\n",
       " '+',\n",
       " 'coats',\n",
       " 'then',\n",
       " 'iron',\n",
       " ',',\n",
       " 'watch',\n",
       " 't.v',\n",
       " '.',\n",
       " 'friday',\n",
       " '.',\n",
       " 'got',\n",
       " 'the',\n",
       " 'all',\n",
       " 'clear',\n",
       " 'of',\n",
       " 'defra',\n",
       " ',',\n",
       " 'just',\n",
       " 'waiting',\n",
       " 'for',\n",
       " 'written',\n",
       " 'confirmation',\n",
       " '.',\n",
       " 'took',\n",
       " 'some',\n",
       " 'of',\n",
       " 'my',\n",
       " 'decorations',\n",
       " 'down',\n",
       " '.',\n",
       " 'went',\n",
       " 'to',\n",
       " 'pick',\n",
       " '[',\n",
       " 'daughter',\n",
       " ']',\n",
       " '+',\n",
       " 'friend',\n",
       " 'up',\n",
       " 'they',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'pictures',\n",
       " 'with',\n",
       " '3',\n",
       " 'other',\n",
       " 'friends',\n",
       " '.',\n",
       " 'friend',\n",
       " 'is',\n",
       " 'staying',\n",
       " 'the',\n",
       " 'night',\n",
       " '.',\n",
       " 'saturday',\n",
       " '.',\n",
       " 'went',\n",
       " 'to',\n",
       " 'see',\n",
       " 'my',\n",
       " 'mam',\n",
       " ',',\n",
       " 'took',\n",
       " 'her',\n",
       " 'some',\n",
       " 'potatoes',\n",
       " '.',\n",
       " '[',\n",
       " 'daughter',\n",
       " '’',\n",
       " 's',\n",
       " 'friend',\n",
       " ']',\n",
       " 'went',\n",
       " 'home',\n",
       " 'about',\n",
       " '6pm',\n",
       " '.',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " '&',\n",
       " 'i',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'pub',\n",
       " '.',\n",
       " 'sat',\n",
       " 'with',\n",
       " 'davis',\n",
       " '.',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " 'had',\n",
       " 'some',\n",
       " 'good',\n",
       " 'game',\n",
       " 'of',\n",
       " 'nominees',\n",
       " 'until',\n",
       " 'we',\n",
       " 'had',\n",
       " 'a',\n",
       " 'power',\n",
       " 'cut',\n",
       " ',',\n",
       " 'baba',\n",
       " 'had',\n",
       " 'to',\n",
       " 'get',\n",
       " 'the',\n",
       " 'candles',\n",
       " 'out',\n",
       " '.',\n",
       " 'it',\n",
       " 'didn',\n",
       " '’',\n",
       " 't',\n",
       " 'stop',\n",
       " 'them',\n",
       " 'from',\n",
       " 'drinking',\n",
       " 'home',\n",
       " 'about',\n",
       " '12',\n",
       " '.',\n",
       " 'sunday',\n",
       " '.',\n",
       " 'had',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'quiet',\n",
       " 'day',\n",
       " ',',\n",
       " 'went',\n",
       " 'to',\n",
       " '[',\n",
       " 'sister',\n",
       " '’',\n",
       " 's',\n",
       " ']',\n",
       " 'for',\n",
       " 'dinner',\n",
       " '.',\n",
       " '[',\n",
       " 'husband',\n",
       " ']',\n",
       " '&',\n",
       " 'the',\n",
       " 'boys',\n",
       " 'were',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'mum' in foot_mouth_df.loc[35,'spell_checked']:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "    \n",
    "foot_mouth_df.loc[35,'spell_checked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "if 'gendefra' in foot_mouth_df.loc[1,'spell_checked']:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so that worked great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Spellcheck issue!\n",
    "\n",
    "So the spellcheck also may have changed a bunch of other important abbreviations so just need to fix those!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Does it have Foot Mouth Disease\" abbreviation?\n",
    "\n",
    "if 'fmd' in foot_mouth_df.loc[1,'spell_checked']:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "    \n",
    "#Does it have Foot Mouth Crisis\" abbreviation?\n",
    "\n",
    "if 'fmc' in foot_mouth_df.loc[83,'spell_checked']:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "\n",
    "#Does it have \"Foot Mouth\" abbreviation?\n",
    "if 'fm' in foot_mouth_df.loc[2,'spell_checked']:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "    \n",
    "#Does it have \"TB\" abbreviation?\n",
    "if 'tb' in foot_mouth_df.loc[1,'spell_checked']:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "\n",
    "#Does it have Sole Occupancy Authentitys\" abbreviation?\n",
    "if 'soa' in foot_mouth_df.loc[2,'spell_checked']:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "    \n",
    "#So I noticed the text also spelt \"DEFRA\" wrong at one point so need to sort that out too!\n",
    "if 'derfa' in foot_mouth_df.loc[1,'spell_checked']:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so its missing FMD and DERFA!\n",
    "So first let's see what everything got changed into:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['information',\n",
       " 'about',\n",
       " 'diarist',\n",
       " 'date',\n",
       " 'of',\n",
       " 'birth',\n",
       " ':',\n",
       " '1975',\n",
       " 'gender',\n",
       " ':',\n",
       " 'm',\n",
       " 'occupation',\n",
       " ':',\n",
       " 'group',\n",
       " '6',\n",
       " 'geographic',\n",
       " 'region',\n",
       " ':',\n",
       " 'north',\n",
       " 'cambria',\n",
       " 'diary',\n",
       " '1',\n",
       " 'thursday',\n",
       " 'meeting',\n",
       " '@',\n",
       " 'n',\n",
       " 'lakes',\n",
       " 'friday',\n",
       " 'tb',\n",
       " 'testing',\n",
       " 'on',\n",
       " 'restoring',\n",
       " 'farm',\n",
       " '.',\n",
       " 'usual',\n",
       " 'chat',\n",
       " 'and',\n",
       " 'defra',\n",
       " 'comments',\n",
       " 'the',\n",
       " 'meeting',\n",
       " '(',\n",
       " 'research',\n",
       " 'panel',\n",
       " 'gp',\n",
       " '6',\n",
       " ')',\n",
       " 'at',\n",
       " 'the',\n",
       " 'north',\n",
       " 'lakes',\n",
       " 'was',\n",
       " 'interesting',\n",
       " '.',\n",
       " 'it',\n",
       " 'surprises',\n",
       " 'me',\n",
       " 'sometimes',\n",
       " 'how',\n",
       " 'people',\n",
       " '(',\n",
       " 'myself',\n",
       " 'included',\n",
       " ')',\n",
       " 'never',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'tire',\n",
       " 'of',\n",
       " 'the',\n",
       " 'same',\n",
       " 'stories',\n",
       " 'and',\n",
       " 'complaints',\n",
       " 'over',\n",
       " 'how',\n",
       " 'the',\n",
       " 'crisis',\n",
       " 'was',\n",
       " 'handled',\n",
       " '.',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'episodes',\n",
       " 'recounted',\n",
       " 'must',\n",
       " 'have',\n",
       " 'been',\n",
       " 'told',\n",
       " 'dozens',\n",
       " 'of',\n",
       " 'times',\n",
       " 'over',\n",
       " 'the',\n",
       " 'last',\n",
       " 'year',\n",
       " 'but',\n",
       " 'whoever',\n",
       " 'says',\n",
       " 'it',\n",
       " 'always',\n",
       " 'seems',\n",
       " 'just',\n",
       " 'as',\n",
       " 'keen',\n",
       " 'to',\n",
       " 'say',\n",
       " 'it',\n",
       " 'again',\n",
       " '–',\n",
       " 'perhaps',\n",
       " 'a',\n",
       " 'reflection',\n",
       " 'of',\n",
       " 'how',\n",
       " 'deeply',\n",
       " 'people',\n",
       " 'feel',\n",
       " 'about',\n",
       " 'the',\n",
       " 'events',\n",
       " 'of',\n",
       " 'the',\n",
       " 'last',\n",
       " 'year',\n",
       " '.',\n",
       " 'having',\n",
       " 'said',\n",
       " 'that',\n",
       " ',',\n",
       " 'most',\n",
       " 'of',\n",
       " 'the',\n",
       " 'resentment',\n",
       " 'and',\n",
       " 'rants',\n",
       " 'that',\n",
       " 'i',\n",
       " 'hear',\n",
       " 'on',\n",
       " 'daily',\n",
       " 'farm',\n",
       " 'visits',\n",
       " 'are',\n",
       " 'focused',\n",
       " 'fairly',\n",
       " 'and',\n",
       " 'squarely',\n",
       " 'at',\n",
       " 'defra',\n",
       " 'and',\n",
       " 'not',\n",
       " 'ffd',\n",
       " 'virus',\n",
       " '.',\n",
       " 'farmers',\n",
       " 'seem',\n",
       " 'far',\n",
       " 'more',\n",
       " 'upset',\n",
       " 'at',\n",
       " 'the',\n",
       " 'construction',\n",
       " 'put',\n",
       " 'on',\n",
       " 'them',\n",
       " 'by',\n",
       " 'defra',\n",
       " 'than',\n",
       " 'they',\n",
       " 'do',\n",
       " 'by',\n",
       " 'the',\n",
       " 'loss',\n",
       " 'of',\n",
       " 'stock',\n",
       " 'now',\n",
       " ',',\n",
       " 'although',\n",
       " 'i',\n",
       " 'know',\n",
       " 'and',\n",
       " 'saw',\n",
       " 'how',\n",
       " 'utterly',\n",
       " 'devastated',\n",
       " 'most',\n",
       " 'were',\n",
       " 'when',\n",
       " 'they',\n",
       " 'were',\n",
       " 'actually',\n",
       " 'diagnosed',\n",
       " 'with',\n",
       " 'the',\n",
       " 'virus',\n",
       " 'and',\n",
       " 'in',\n",
       " 'the']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For fmd\n",
    "\n",
    "foot_mouth_df.loc[0,'spell_checked'][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['information',\n",
       " 'about',\n",
       " 'diarist',\n",
       " 'date',\n",
       " 'of',\n",
       " 'birth',\n",
       " ':',\n",
       " '1966',\n",
       " 'gender',\n",
       " ':',\n",
       " 'f',\n",
       " 'occupation',\n",
       " ':',\n",
       " 'group',\n",
       " '6',\n",
       " 'geographic',\n",
       " 'region',\n",
       " ':',\n",
       " 'north',\n",
       " 'cumbria',\n",
       " 'diary',\n",
       " '1',\n",
       " 'monday',\n",
       " 'was',\n",
       " 'the',\n",
       " 'usual',\n",
       " 'long',\n",
       " 'hard',\n",
       " 'grind',\n",
       " '.',\n",
       " 'i',\n",
       " 'accept',\n",
       " 'that',\n",
       " 'i',\n",
       " 'have',\n",
       " 'to',\n",
       " 'put',\n",
       " 'in',\n",
       " '10',\n",
       " '–',\n",
       " '12',\n",
       " 'hours',\n",
       " 'and',\n",
       " 'i',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'mind',\n",
       " 'doing',\n",
       " 'the',\n",
       " 'work',\n",
       " 'because',\n",
       " 'it',\n",
       " '’',\n",
       " 's',\n",
       " 'not',\n",
       " 'physically',\n",
       " 'or',\n",
       " 'mentally',\n",
       " 'taxing',\n",
       " 'but',\n",
       " 'i',\n",
       " 'do',\n",
       " 'hate',\n",
       " 'not',\n",
       " 'having',\n",
       " 'a',\n",
       " 'lunch',\n",
       " 'break',\n",
       " ',',\n",
       " 'just',\n",
       " 'that',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'selfish',\n",
       " 'time',\n",
       " 'to',\n",
       " 'site',\n",
       " ',',\n",
       " 'have',\n",
       " 'a',\n",
       " 'cigarette',\n",
       " ',',\n",
       " 'take',\n",
       " 'the',\n",
       " 'dogs',\n",
       " 'down',\n",
       " 'the',\n",
       " 'river',\n",
       " ',',\n",
       " 'see',\n",
       " 'the',\n",
       " 'horses…whatever',\n",
       " '.',\n",
       " 'i',\n",
       " 'do',\n",
       " 'resent',\n",
       " 'that',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'w',\n",
       " '(',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'bosses',\n",
       " ')',\n",
       " 'almost',\n",
       " 'always',\n",
       " 'gets',\n",
       " 'a',\n",
       " 'lunch',\n",
       " 'hour',\n",
       " '.',\n",
       " 'b',\n",
       " '(',\n",
       " 'the',\n",
       " 'other',\n",
       " 'boss',\n",
       " ')',\n",
       " 'has',\n",
       " 'gone',\n",
       " 'up',\n",
       " 'tremendously',\n",
       " 'in',\n",
       " 'my',\n",
       " 'opinion',\n",
       " 'for',\n",
       " 'the',\n",
       " 'way',\n",
       " 'that',\n",
       " 'he',\n",
       " 'gets',\n",
       " 'on',\n",
       " 'with',\n",
       " 'the',\n",
       " 'work',\n",
       " '.',\n",
       " 'he',\n",
       " 'starts',\n",
       " 'early',\n",
       " ',',\n",
       " 'finishes',\n",
       " 'late',\n",
       " ',',\n",
       " 'hates',\n",
       " 'derfa',\n",
       " 'paperwork',\n",
       " 'and',\n",
       " 'rarely',\n",
       " 'complains',\n",
       " '.',\n",
       " 'it',\n",
       " 'is',\n",
       " 'definitely',\n",
       " 'grinding',\n",
       " 'them',\n",
       " 'down',\n",
       " 'because',\n",
       " 'they',\n",
       " 'work',\n",
       " 'like',\n",
       " 'that',\n",
       " 'at',\n",
       " 'least',\n",
       " '4',\n",
       " 'days',\n",
       " 'a',\n",
       " 'week',\n",
       " '.',\n",
       " 'it',\n",
       " 'has',\n",
       " 'been',\n",
       " 'a',\n",
       " 'huge',\n",
       " 'advantage',\n",
       " 'this',\n",
       " 'last',\n",
       " 'year',\n",
       " 'being',\n",
       " 'part-time',\n",
       " 'at',\n",
       " 'work',\n",
       " '.',\n",
       " 'my',\n",
       " 'days',\n",
       " 'off',\n",
       " 'obviously',\n",
       " 'aren',\n",
       " '’',\n",
       " 't',\n",
       " 'my',\n",
       " 'own',\n",
       " 'as',\n",
       " 'they',\n",
       " 'used',\n",
       " 'to',\n",
       " 'be',\n",
       " ',']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For DERFA, \n",
    "foot_mouth_df.loc[1,'txt_lower'][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so looks like \"DERFA\" actually got sorted out in the initial spellcheck (i'm guessing it alonf with DEFRA got changed to \"der\" so did a 2-in-1 with that one!\n",
    "\n",
    "FMD on the other hand got changed to \"ffd\" so just need to change that quickly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacement_mapping_2(x):\n",
    "        if x == \"ffd\":\n",
    "            return re.sub(\"ffd\",\"fmd\",x)\n",
    "        else:\n",
    "            return x  \n",
    "foot_mouth_df[\"spell_checked\"] = foot_mouth_df[\"spell_checked\"].apply(lambda x:[replacement_mapping_2(w) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if 'fmd' in foot_mouth_df.loc[1,'spell_checked']:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RegEx replacements\n",
    "\n",
    "*Okay so don't really know what I would need to be replacing, will have to do word counts to see if there are words like this - sooooooo:\n",
    "\n",
    "**[IGNORE FOR NOW]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RegEx stands for REGular EXpressions, which is probably familiar to you as the basis for how find-and-replace works in text documents. I mentioned this above when I talked about cutting up a large file into smaller files whenever the computer iterating over the large file found one of three specific combinations of numbers and symbols. \n",
    "\n",
    "But RegEx is actually stronger than that because you can use it to identify combinations of letters, numbers, symbols, spaces and more, some of which can be repeated more than once or can be optional. I won't go into RegEx too much more here, because that is a whole set of lessons on its own. But here are a couple of examples that you might find useful in a text like ours where we know that there are mixtures of numbers written as numbers, numbers spelled out, geographic abbreviations and more.\n",
    "\n",
    "As you might expect, do the Run/Shift+Enter thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_numbers = [re.sub(r\"ninety-six\", \"96\", word) for word in corpus_words]   # Defines a new variable create by substituting\n",
    "                                                                                # '96' for 'ninety-six' in corpus_words\n",
    "\n",
    "print(corpus_numbers[:100])                                            # Prints the first 100 items in the newly created corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super! Now, this only works on 'ninety-six', but there might be other numbers spelled out in the text. We would have to look at it all to be sure, either manually or by using word frequency tables (we'll get to that). If we were to find some, we would have to revise our RegEx to capture more things and substitute them properly. \n",
    "\n",
    "One way to do that might be to define multiple terms to replace and what to replace them with. To do that, I searched on stack overflow and found a function written to multiple items by RegEx in a string. \n",
    "\n",
    "Run/Shift+Enter below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_replace(dict, text):\n",
    "  # Create a regular expression  from the dictionary keys\n",
    "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "    \n",
    "\n",
    "  # For each match, look-up corresponding value in dictionary\n",
    "  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text) \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "\n",
    "  dict = {\n",
    "    \"CA\" : \"California\",\n",
    "    \"United Kingdom\" : \"U.K\",\n",
    "    \"United Kingdom of Great Britain\" : \"U.K\",\n",
    "    \"United Kingdom of Great Britain and Northern Ireland\" : \"U.K\",\n",
    "    \"UK\" : \"U.K\",\n",
    "    \"Privacy Policy\" : \"noodle soup\",\n",
    "  } \n",
    "\n",
    "corpus_replace = multiple_replace(dict, corpus)\n",
    "\n",
    "print(corpus_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh-oh!\n",
    "\n",
    "It worked for \"The United Kingdom\" and \"the UK\" but for some reason:\n",
    "* \"United Kingdom of Great Britain\" became \"U.K of Great Britain\" and \n",
    "* \"United Kingdom of Great Britain and Northern Ireland\" became \"U.K of Great Britain and Northern Ireland \"\n",
    "\n",
    "\n",
    "Let's try editing this!\n",
    "What happens when we use lowercase letters instead of uppercase letters in \"United Kingdom\"? \n",
    "\n",
    "**Ans:**\"the United Kingdom\" stays untouched\n",
    "\n",
    "What happens if you change the order of the entries in 'dict'? For example What happens if you reverse the order of-\n",
    "- \"United Kingdom of Great Britain and Northern Ireland\" : \"U.K.\", and \n",
    "- \"United Kingdom of Great Britain\" : \"U.K.\", ? \n",
    "\n",
    "**Ans:** \"United Kingdom of Great Britain and Northern Ireland\" ACTUALLY gets changed to \"U.K\"! Interesting :)\n",
    "\n",
    "Okay so let's try doing this properly:\n",
    "\n",
    "(You should also feel free to add your own lines to 'dict' to exact some substitutions of your own.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "\n",
    "  dict = {\n",
    "    \"CA\" : \"California\",\n",
    "    \"United Kingdom of Great Britain and Northern Ireland\" : \"U.K\",\n",
    "    \"United Kingdom of Great Britain\" : \"U.K\",\n",
    "    \"United Kingdom\" : \"U.K\",\n",
    "    \"UK\" : \"U.K\",\n",
    "    \"ninety-six\": \"96\",\n",
    "    \"Privacy Policy\": \"noodle soup\",\n",
    "  } \n",
    "\n",
    "corpus_correct_replace = multiple_replace(dict, corpus)\n",
    "\n",
    "print(corpus_correct_replace)\n",
    "# et voila it should work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Summarise: \n",
    "> 1) Pay attention to capitalisation when trying to replace entries\n",
    ">\n",
    "> 2) The order of the entries matter, so put smaller terms (\"United Kingdom\") **after** the bigger term (\"United Kingdom of Great Britain\") otherwise you will run into issues!\n",
    "\n",
    "Note: this function works on strings, so I applied it to 'corpus' our original raw text. \n",
    "We can either put a step like this as the first step in a pipeline, or we can adapt the code to iterate over a list of strings. Both have pros and cons. What do you think those pros and cons might be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing irrelevancies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punctuation is not always very useful for understanding text, especially if you look at words as tokens because lots of the punctuation ends up being tokenised on its own. \n",
    "\n",
    "We could use RegEx to replace all punctuation with nothing, and that is a valid approach. But, just for variety sake, I demonstrate another way here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________\n",
    "Forging ahead, let's filter out punctuation. We can define a string that includes all the standard English language punctuation, and then use that to iterate over the relevant foot_mouth DataFrame column, removing anything that matches.\n",
    "\n",
    "But wait... Do we really want to remove the:\n",
    "- hyphens in things like 'ninety-six' or words like 'lactose-free'? \n",
    "- full stops in things like 'u.k.'? \n",
    "- the apostrophe in contractions or possessives?\n",
    "\n",
    "There are no right or wrong answers here. Every project will have to decide, based on the research questions, what is the right choice for the specific context. In this case, we want to remove the full stops, even from 'u.k.' so that it becomes identical to 'uk'. \n",
    "\n",
    "But, at the same time, we don't necessarily want to remove apostrophes. That is a punctuation mark that occurs in the middle of words and do add meaning to the word, so I want to keep them. \n",
    "\n",
    "Run/Shift+Enter, as is tradition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&()*+,./:;<=>?@[\\]^_`{|}~“”-\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>tokenised_words</th>\n",
       "      <th>txt_lower</th>\n",
       "      <th>spell_checked</th>\n",
       "      <th>no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5407diary02.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5407diary03.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1966...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5407diary07.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5407diary08.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1963...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5407diary09.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1981...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5407diary10.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1937...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5407diary13.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1947...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5407diary14.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5407diary15.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1949...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5407diary16.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5407diary17.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1936...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>5407diary18.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>5407diary19.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>5407diary21.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>5407diary22.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>5407diary23.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5407diary24.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5407diary26.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5407diary27.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>5407diary28.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>5407diary29.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>5407diary30.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>5407diary31.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>5407diary32.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>5407diary34.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>5407diary36.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>5407diary37.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>5407diary39.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>5407diary40.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>5407diary41.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>5407diary42.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>5407diary43.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>5407diary44.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>5407diary47.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>5407diary48.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>5407diary49.rtf</td>\n",
       "      <td>\\t\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>5407diary52.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>5407diary53.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>5407diary54.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>5407diary55.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>5407fg01.rtf</td>\n",
       "      <td>\\nGroups Discussion with Members of  Farmers F...</td>\n",
       "      <td>[Groups, Discussion, with, Members, of, Farmer...</td>\n",
       "      <td>[groups, discussion, with, members, of, farmer...</td>\n",
       "      <td>[groups, discussion, with, members, of, farmer...</td>\n",
       "      <td>[groups, discussion, with, members, of, farmer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>5407fg02.rtf</td>\n",
       "      <td>Groups Discussion with Members of Small Busine...</td>\n",
       "      <td>[Groups, Discussion, with, Members, of, Small,...</td>\n",
       "      <td>[groups, discussion, with, members, of, small,...</td>\n",
       "      <td>[groups, discussion, with, members, of, small,...</td>\n",
       "      <td>[groups, discussion, with, members, of, small,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>5407fg03.rtf</td>\n",
       "      <td>\\n\\nGroups Discussion with Members of  Agricul...</td>\n",
       "      <td>[Groups, Discussion, with, Members, of, Agricu...</td>\n",
       "      <td>[groups, discussion, with, members, of, agricu...</td>\n",
       "      <td>[groups, discussion, with, members, of, agricu...</td>\n",
       "      <td>[groups, discussion, with, members, of, agricu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>5407fg04.rtf</td>\n",
       "      <td>\\nNO AUDIO RECORDING\\n\\nGroups Discussion with...</td>\n",
       "      <td>[NO, AUDIO, RECORDING, Groups, Discussion, wit...</td>\n",
       "      <td>[no, audio, recording, groups, discussion, wit...</td>\n",
       "      <td>[no, audio, recording, groups, discussion, wit...</td>\n",
       "      <td>[no, audio, recording, groups, discussion, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>5407fg05.rtf</td>\n",
       "      <td>\\n\\nGroups Discussion with Community Group of ...</td>\n",
       "      <td>[Groups, Discussion, with, Community, Group, o...</td>\n",
       "      <td>[groups, discussion, with, community, group, o...</td>\n",
       "      <td>[groups, discussion, with, community, group, o...</td>\n",
       "      <td>[groups, discussion, with, community, group, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>5407fg06.rtf</td>\n",
       "      <td>\\n\\nGroup Discussion Panel Members, Group 6 – ...</td>\n",
       "      <td>[Group, Discussion, Panel, Members, ,, Group, ...</td>\n",
       "      <td>[group, discussion, panel, members, ,, group, ...</td>\n",
       "      <td>[group, discussion, panel, members, ,, group, ...</td>\n",
       "      <td>[group, discussion, panel, members, , group, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>5407int02.rtf</td>\n",
       "      <td>\\nDate of Interview: 14/03/02\\n\\nInformation a...</td>\n",
       "      <td>[Date, of, Interview, :, 14/03/02, Information...</td>\n",
       "      <td>[date, of, interview, :, 14/03/02, information...</td>\n",
       "      <td>[date, of, interview, :, 14/03/02, information...</td>\n",
       "      <td>[date, of, interview, , 140302, information, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>5407int03.rtf</td>\n",
       "      <td>\\nDate of Interview: 08/03/02\\n\\nInformation a...</td>\n",
       "      <td>[Date, of, Interview, :, 08/03/02, Information...</td>\n",
       "      <td>[date, of, interview, :, 08/03/02, information...</td>\n",
       "      <td>[date, of, interview, :, 08/03/02, information...</td>\n",
       "      <td>[date, of, interview, , 080302, information, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>5407int07.rtf</td>\n",
       "      <td>\\nDate of Interview: 14/03/02\\n\\nInformation a...</td>\n",
       "      <td>[Date, of, Interview, :, 14/03/02, Information...</td>\n",
       "      <td>[date, of, interview, :, 14/03/02, information...</td>\n",
       "      <td>[date, of, interview, :, 14/03/02, information...</td>\n",
       "      <td>[date, of, interview, , 140302, information, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>5407int08.rtf</td>\n",
       "      <td>\\nDate of Interview: 06/03/02\\n\\nInformation a...</td>\n",
       "      <td>[Date, of, Interview, :, 06/03/02, Information...</td>\n",
       "      <td>[date, of, interview, :, 06/03/02, information...</td>\n",
       "      <td>[date, of, interview, :, 06/03/02, information...</td>\n",
       "      <td>[date, of, interview, , 060302, information, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number         Filename  \\\n",
       "0        0  5407diary02.rtf   \n",
       "1        1  5407diary03.rtf   \n",
       "2        2  5407diary07.rtf   \n",
       "3        3  5407diary08.rtf   \n",
       "4        4  5407diary09.rtf   \n",
       "5        5  5407diary10.rtf   \n",
       "6        6  5407diary13.rtf   \n",
       "7        7  5407diary14.rtf   \n",
       "8        8  5407diary15.rtf   \n",
       "9        9  5407diary16.rtf   \n",
       "10      10  5407diary17.rtf   \n",
       "11      11  5407diary18.rtf   \n",
       "12      12  5407diary19.rtf   \n",
       "13      13  5407diary21.rtf   \n",
       "14      14  5407diary22.rtf   \n",
       "15      15  5407diary23.rtf   \n",
       "16      16  5407diary24.rtf   \n",
       "17      17  5407diary26.rtf   \n",
       "18      18  5407diary27.rtf   \n",
       "19      19  5407diary28.rtf   \n",
       "20      20  5407diary29.rtf   \n",
       "21      21  5407diary30.rtf   \n",
       "22      22  5407diary31.rtf   \n",
       "23      23  5407diary32.rtf   \n",
       "24      24  5407diary34.rtf   \n",
       "25      25  5407diary36.rtf   \n",
       "26      26  5407diary37.rtf   \n",
       "27      27  5407diary39.rtf   \n",
       "28      28  5407diary40.rtf   \n",
       "29      29  5407diary41.rtf   \n",
       "30      30  5407diary42.rtf   \n",
       "31      31  5407diary43.rtf   \n",
       "32      32  5407diary44.rtf   \n",
       "33      33  5407diary47.rtf   \n",
       "34      34  5407diary48.rtf   \n",
       "35      35  5407diary49.rtf   \n",
       "36      36  5407diary52.rtf   \n",
       "37      37  5407diary53.rtf   \n",
       "38      38  5407diary54.rtf   \n",
       "39      39  5407diary55.rtf   \n",
       "40      40     5407fg01.rtf   \n",
       "41      41     5407fg02.rtf   \n",
       "42      42     5407fg03.rtf   \n",
       "43      43     5407fg04.rtf   \n",
       "44      44     5407fg05.rtf   \n",
       "45      45     5407fg06.rtf   \n",
       "46      46    5407int02.rtf   \n",
       "47      47    5407int03.rtf   \n",
       "48      48    5407int07.rtf   \n",
       "49      49    5407int08.rtf   \n",
       "\n",
       "                                      everything_else  \\\n",
       "0   \\n\\nInformation about diarist\\nDate of birth: ...   \n",
       "1   Information about diarist\\nDate of birth: 1966...   \n",
       "2   \\n\\nInformation about diarist\\nDate of birth: ...   \n",
       "3   Information about diarist\\nDate of birth: 1963...   \n",
       "4   Information about diarist\\nDate of birth: 1981...   \n",
       "5   Information about diarist\\nDate of birth: 1937...   \n",
       "6   Information about diarist\\nDate of birth: 1947...   \n",
       "7   \\nInformation about diarist\\nDate of birth: 19...   \n",
       "8   Information about diarist\\nDate of birth: 1949...   \n",
       "9   \\nInformation about diarist\\nDate of birth: 19...   \n",
       "10  Information about diarist\\nDate of birth: 1936...   \n",
       "11  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "12  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "13  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "14  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "15  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "16  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "17  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "18  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "19  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "20  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "21  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "22  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "23  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "24  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "25  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "26  \\n\\nInformation about diarist\\nDate of birth: ...   \n",
       "27  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "28  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "29  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "30  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "31  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "32  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "33  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "34  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "35  \\t\\nInformation about diarist\\nDate of birth: ...   \n",
       "36  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "37  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "38  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "39  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "40  \\nGroups Discussion with Members of  Farmers F...   \n",
       "41  Groups Discussion with Members of Small Busine...   \n",
       "42  \\n\\nGroups Discussion with Members of  Agricul...   \n",
       "43  \\nNO AUDIO RECORDING\\n\\nGroups Discussion with...   \n",
       "44  \\n\\nGroups Discussion with Community Group of ...   \n",
       "45  \\n\\nGroup Discussion Panel Members, Group 6 – ...   \n",
       "46  \\nDate of Interview: 14/03/02\\n\\nInformation a...   \n",
       "47  \\nDate of Interview: 08/03/02\\n\\nInformation a...   \n",
       "48  \\nDate of Interview: 14/03/02\\n\\nInformation a...   \n",
       "49  \\nDate of Interview: 06/03/02\\n\\nInformation a...   \n",
       "\n",
       "                                      tokenised_words  \\\n",
       "0   [Information, about, diarist, Date, of, birth,...   \n",
       "1   [Information, about, diarist, Date, of, birth,...   \n",
       "2   [Information, about, diarist, Date, of, birth,...   \n",
       "3   [Information, about, diarist, Date, of, birth,...   \n",
       "4   [Information, about, diarist, Date, of, birth,...   \n",
       "5   [Information, about, diarist, Date, of, birth,...   \n",
       "6   [Information, about, diarist, Date, of, birth,...   \n",
       "7   [Information, about, diarist, Date, of, birth,...   \n",
       "8   [Information, about, diarist, Date, of, birth,...   \n",
       "9   [Information, about, diarist, Date, of, birth,...   \n",
       "10  [Information, about, diarist, Date, of, birth,...   \n",
       "11  [Information, about, diarist, Date, of, birth,...   \n",
       "12  [Information, about, diarist, Date, of, birth,...   \n",
       "13  [Information, about, diarist, Date, of, birth,...   \n",
       "14  [Information, about, diarist, Date, of, birth,...   \n",
       "15  [Information, about, diarist, Date, of, birth,...   \n",
       "16  [Information, about, diarist, Date, of, birth,...   \n",
       "17  [Information, about, diarist, Date, of, birth,...   \n",
       "18  [Information, about, diarist, Date, of, birth,...   \n",
       "19  [Information, about, diarist, Date, of, birth,...   \n",
       "20  [Information, about, diarist, Date, of, birth,...   \n",
       "21  [Information, about, diarist, Date, of, birth,...   \n",
       "22  [Information, about, diarist, Date, of, birth,...   \n",
       "23  [Information, about, diarist, Date, of, birth,...   \n",
       "24  [Information, about, diarist, Date, of, birth,...   \n",
       "25  [Information, about, diarist, Date, of, birth,...   \n",
       "26  [Information, about, diarist, Date, of, birth,...   \n",
       "27  [Information, about, diarist, Date, of, birth,...   \n",
       "28  [Information, about, diarist, Date, of, birth,...   \n",
       "29  [Information, about, diarist, Date, of, birth,...   \n",
       "30  [Information, about, diarist, Date, of, birth,...   \n",
       "31  [Information, about, diarist, Date, of, birth,...   \n",
       "32  [Information, about, diarist, Date, of, birth,...   \n",
       "33  [Information, about, diarist, Date, of, birth,...   \n",
       "34  [Information, about, diarist, Date, of, birth,...   \n",
       "35  [Information, about, diarist, Date, of, birth,...   \n",
       "36  [Information, about, diarist, Date, of, birth,...   \n",
       "37  [Information, about, diarist, Date, of, birth,...   \n",
       "38  [Information, about, diarist, Date, of, birth,...   \n",
       "39  [Information, about, diarist, Date, of, birth,...   \n",
       "40  [Groups, Discussion, with, Members, of, Farmer...   \n",
       "41  [Groups, Discussion, with, Members, of, Small,...   \n",
       "42  [Groups, Discussion, with, Members, of, Agricu...   \n",
       "43  [NO, AUDIO, RECORDING, Groups, Discussion, wit...   \n",
       "44  [Groups, Discussion, with, Community, Group, o...   \n",
       "45  [Group, Discussion, Panel, Members, ,, Group, ...   \n",
       "46  [Date, of, Interview, :, 14/03/02, Information...   \n",
       "47  [Date, of, Interview, :, 08/03/02, Information...   \n",
       "48  [Date, of, Interview, :, 14/03/02, Information...   \n",
       "49  [Date, of, Interview, :, 06/03/02, Information...   \n",
       "\n",
       "                                            txt_lower  \\\n",
       "0   [information, about, diarist, date, of, birth,...   \n",
       "1   [information, about, diarist, date, of, birth,...   \n",
       "2   [information, about, diarist, date, of, birth,...   \n",
       "3   [information, about, diarist, date, of, birth,...   \n",
       "4   [information, about, diarist, date, of, birth,...   \n",
       "5   [information, about, diarist, date, of, birth,...   \n",
       "6   [information, about, diarist, date, of, birth,...   \n",
       "7   [information, about, diarist, date, of, birth,...   \n",
       "8   [information, about, diarist, date, of, birth,...   \n",
       "9   [information, about, diarist, date, of, birth,...   \n",
       "10  [information, about, diarist, date, of, birth,...   \n",
       "11  [information, about, diarist, date, of, birth,...   \n",
       "12  [information, about, diarist, date, of, birth,...   \n",
       "13  [information, about, diarist, date, of, birth,...   \n",
       "14  [information, about, diarist, date, of, birth,...   \n",
       "15  [information, about, diarist, date, of, birth,...   \n",
       "16  [information, about, diarist, date, of, birth,...   \n",
       "17  [information, about, diarist, date, of, birth,...   \n",
       "18  [information, about, diarist, date, of, birth,...   \n",
       "19  [information, about, diarist, date, of, birth,...   \n",
       "20  [information, about, diarist, date, of, birth,...   \n",
       "21  [information, about, diarist, date, of, birth,...   \n",
       "22  [information, about, diarist, date, of, birth,...   \n",
       "23  [information, about, diarist, date, of, birth,...   \n",
       "24  [information, about, diarist, date, of, birth,...   \n",
       "25  [information, about, diarist, date, of, birth,...   \n",
       "26  [information, about, diarist, date, of, birth,...   \n",
       "27  [information, about, diarist, date, of, birth,...   \n",
       "28  [information, about, diarist, date, of, birth,...   \n",
       "29  [information, about, diarist, date, of, birth,...   \n",
       "30  [information, about, diarist, date, of, birth,...   \n",
       "31  [information, about, diarist, date, of, birth,...   \n",
       "32  [information, about, diarist, date, of, birth,...   \n",
       "33  [information, about, diarist, date, of, birth,...   \n",
       "34  [information, about, diarist, date, of, birth,...   \n",
       "35  [information, about, diarist, date, of, birth,...   \n",
       "36  [information, about, diarist, date, of, birth,...   \n",
       "37  [information, about, diarist, date, of, birth,...   \n",
       "38  [information, about, diarist, date, of, birth,...   \n",
       "39  [information, about, diarist, date, of, birth,...   \n",
       "40  [groups, discussion, with, members, of, farmer...   \n",
       "41  [groups, discussion, with, members, of, small,...   \n",
       "42  [groups, discussion, with, members, of, agricu...   \n",
       "43  [no, audio, recording, groups, discussion, wit...   \n",
       "44  [groups, discussion, with, community, group, o...   \n",
       "45  [group, discussion, panel, members, ,, group, ...   \n",
       "46  [date, of, interview, :, 14/03/02, information...   \n",
       "47  [date, of, interview, :, 08/03/02, information...   \n",
       "48  [date, of, interview, :, 14/03/02, information...   \n",
       "49  [date, of, interview, :, 06/03/02, information...   \n",
       "\n",
       "                                        spell_checked  \\\n",
       "0   [information, about, diarist, date, of, birth,...   \n",
       "1   [information, about, diarist, date, of, birth,...   \n",
       "2   [information, about, diarist, date, of, birth,...   \n",
       "3   [information, about, diarist, date, of, birth,...   \n",
       "4   [information, about, diarist, date, of, birth,...   \n",
       "5   [information, about, diarist, date, of, birth,...   \n",
       "6   [information, about, diarist, date, of, birth,...   \n",
       "7   [information, about, diarist, date, of, birth,...   \n",
       "8   [information, about, diarist, date, of, birth,...   \n",
       "9   [information, about, diarist, date, of, birth,...   \n",
       "10  [information, about, diarist, date, of, birth,...   \n",
       "11  [information, about, diarist, date, of, birth,...   \n",
       "12  [information, about, diarist, date, of, birth,...   \n",
       "13  [information, about, diarist, date, of, birth,...   \n",
       "14  [information, about, diarist, date, of, birth,...   \n",
       "15  [information, about, diarist, date, of, birth,...   \n",
       "16  [information, about, diarist, date, of, birth,...   \n",
       "17  [information, about, diarist, date, of, birth,...   \n",
       "18  [information, about, diarist, date, of, birth,...   \n",
       "19  [information, about, diarist, date, of, birth,...   \n",
       "20  [information, about, diarist, date, of, birth,...   \n",
       "21  [information, about, diarist, date, of, birth,...   \n",
       "22  [information, about, diarist, date, of, birth,...   \n",
       "23  [information, about, diarist, date, of, birth,...   \n",
       "24  [information, about, diarist, date, of, birth,...   \n",
       "25  [information, about, diarist, date, of, birth,...   \n",
       "26  [information, about, diarist, date, of, birth,...   \n",
       "27  [information, about, diarist, date, of, birth,...   \n",
       "28  [information, about, diarist, date, of, birth,...   \n",
       "29  [information, about, diarist, date, of, birth,...   \n",
       "30  [information, about, diarist, date, of, birth,...   \n",
       "31  [information, about, diarist, date, of, birth,...   \n",
       "32  [information, about, diarist, date, of, birth,...   \n",
       "33  [information, about, diarist, date, of, birth,...   \n",
       "34  [information, about, diarist, date, of, birth,...   \n",
       "35  [information, about, diarist, date, of, birth,...   \n",
       "36  [information, about, diarist, date, of, birth,...   \n",
       "37  [information, about, diarist, date, of, birth,...   \n",
       "38  [information, about, diarist, date, of, birth,...   \n",
       "39  [information, about, diarist, date, of, birth,...   \n",
       "40  [groups, discussion, with, members, of, farmer...   \n",
       "41  [groups, discussion, with, members, of, small,...   \n",
       "42  [groups, discussion, with, members, of, agricu...   \n",
       "43  [no, audio, recording, groups, discussion, wit...   \n",
       "44  [groups, discussion, with, community, group, o...   \n",
       "45  [group, discussion, panel, members, ,, group, ...   \n",
       "46  [date, of, interview, :, 14/03/02, information...   \n",
       "47  [date, of, interview, :, 08/03/02, information...   \n",
       "48  [date, of, interview, :, 14/03/02, information...   \n",
       "49  [date, of, interview, :, 06/03/02, information...   \n",
       "\n",
       "                                             no_punct  \n",
       "0   [information, about, diarist, date, of, birth,...  \n",
       "1   [information, about, diarist, date, of, birth,...  \n",
       "2   [information, about, diarist, date, of, birth,...  \n",
       "3   [information, about, diarist, date, of, birth,...  \n",
       "4   [information, about, diarist, date, of, birth,...  \n",
       "5   [information, about, diarist, date, of, birth,...  \n",
       "6   [information, about, diarist, date, of, birth,...  \n",
       "7   [information, about, diarist, date, of, birth,...  \n",
       "8   [information, about, diarist, date, of, birth,...  \n",
       "9   [information, about, diarist, date, of, birth,...  \n",
       "10  [information, about, diarist, date, of, birth,...  \n",
       "11  [information, about, diarist, date, of, birth,...  \n",
       "12  [information, about, diarist, date, of, birth,...  \n",
       "13  [information, about, diarist, date, of, birth,...  \n",
       "14  [information, about, diarist, date, of, birth,...  \n",
       "15  [information, about, diarist, date, of, birth,...  \n",
       "16  [information, about, diarist, date, of, birth,...  \n",
       "17  [information, about, diarist, date, of, birth,...  \n",
       "18  [information, about, diarist, date, of, birth,...  \n",
       "19  [information, about, diarist, date, of, birth,...  \n",
       "20  [information, about, diarist, date, of, birth,...  \n",
       "21  [information, about, diarist, date, of, birth,...  \n",
       "22  [information, about, diarist, date, of, birth,...  \n",
       "23  [information, about, diarist, date, of, birth,...  \n",
       "24  [information, about, diarist, date, of, birth,...  \n",
       "25  [information, about, diarist, date, of, birth,...  \n",
       "26  [information, about, diarist, date, of, birth,...  \n",
       "27  [information, about, diarist, date, of, birth,...  \n",
       "28  [information, about, diarist, date, of, birth,...  \n",
       "29  [information, about, diarist, date, of, birth,...  \n",
       "30  [information, about, diarist, date, of, birth,...  \n",
       "31  [information, about, diarist, date, of, birth,...  \n",
       "32  [information, about, diarist, date, of, birth,...  \n",
       "33  [information, about, diarist, date, of, birth,...  \n",
       "34  [information, about, diarist, date, of, birth,...  \n",
       "35  [information, about, diarist, date, of, birth,...  \n",
       "36  [information, about, diarist, date, of, birth,...  \n",
       "37  [information, about, diarist, date, of, birth,...  \n",
       "38  [information, about, diarist, date, of, birth,...  \n",
       "39  [information, about, diarist, date, of, birth,...  \n",
       "40  [groups, discussion, with, members, of, farmer...  \n",
       "41  [groups, discussion, with, members, of, small,...  \n",
       "42  [groups, discussion, with, members, of, agricu...  \n",
       "43  [no, audio, recording, groups, discussion, wit...  \n",
       "44  [groups, discussion, with, community, group, o...  \n",
       "45  [group, discussion, panel, members, , group, 6...  \n",
       "46  [date, of, interview, , 140302, information, a...  \n",
       "47  [date, of, interview, , 080302, information, a...  \n",
       "48  [date, of, interview, , 140302, information, a...  \n",
       "49  [date, of, interview, , 060302, information, a...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "English_punctuation = \"!\\\"#$%&()*+,./:;<=>?@[\\]^_`{|}~“”-\"      # Define a variable with all the punctuation to remove.\n",
    "print(English_punctuation)                                     # Print that defined variable, just to check it is correct.\n",
    "print(\"...\") \n",
    "\n",
    "\n",
    "def remove_punctuation(from_text):                           # Had to define a function to iterate over the strings in a row\n",
    "    table = str.maketrans('', '', English_punctuation)       # The python function 'maketrans' creates a table that maps\n",
    "    stripped = [w.translate(table) for w in from_text]        # the punctation marks to 'None'. Print the table to check. \n",
    "    return stripped\n",
    "\n",
    "\n",
    "foot_mouth_df['no_punct'] = [remove_punctuation(i) for i in foot_mouth_df['spell_checked']] # Iterating above function to each\n",
    "foot_mouth_df[:50]                                                                      # row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yayyy no errors! Just need to quickly inspect some of the rows to see if it ACTUALLY removed the punctuation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_mouth_df.loc[2,'no_punct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_mouth_df.loc[50,'no_punct']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked!!\n",
    "\n",
    "Did you notice that removing the punctuation has left list items that are empty strings. Between 'corpus' and 'it', for example, is an item shown as ''. This is an empty string item that was a full stop before we removed the punctuation. \n",
    "\n",
    "Why do you think these empty string items are included in the output list? \n",
    "Can you think of how we might remove this?\n",
    "Since those empty strings are python-recognised instances of 'None',  python can find and filter them out. \n",
    "\n",
    "Let's give it a try. Run/Shift+Enter. Do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_mouth_df['no_punct_no_space'] = [list(filter(None, sublist)) for sublist in foot_mouth_df['no_punct']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>tokenised_words</th>\n",
       "      <th>txt_lower</th>\n",
       "      <th>spell_checked</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>no_punct_no_space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5407diary02.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5407diary03.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1966...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5407diary07.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5407diary08.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1963...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5407diary09.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1981...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5407diary10.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1937...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5407diary13.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1947...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5407diary14.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5407diary15.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1949...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5407diary16.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>[Information, about, diarist, Date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "      <td>[information, about, diarist, date, of, birth,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number         Filename                                    everything_else  \\\n",
       "0       0  5407diary02.rtf  \\n\\nInformation about diarist\\nDate of birth: ...   \n",
       "1       1  5407diary03.rtf  Information about diarist\\nDate of birth: 1966...   \n",
       "2       2  5407diary07.rtf  \\n\\nInformation about diarist\\nDate of birth: ...   \n",
       "3       3  5407diary08.rtf  Information about diarist\\nDate of birth: 1963...   \n",
       "4       4  5407diary09.rtf  Information about diarist\\nDate of birth: 1981...   \n",
       "5       5  5407diary10.rtf  Information about diarist\\nDate of birth: 1937...   \n",
       "6       6  5407diary13.rtf  Information about diarist\\nDate of birth: 1947...   \n",
       "7       7  5407diary14.rtf  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "8       8  5407diary15.rtf  Information about diarist\\nDate of birth: 1949...   \n",
       "9       9  5407diary16.rtf  \\nInformation about diarist\\nDate of birth: 19...   \n",
       "\n",
       "                                     tokenised_words  \\\n",
       "0  [Information, about, diarist, Date, of, birth,...   \n",
       "1  [Information, about, diarist, Date, of, birth,...   \n",
       "2  [Information, about, diarist, Date, of, birth,...   \n",
       "3  [Information, about, diarist, Date, of, birth,...   \n",
       "4  [Information, about, diarist, Date, of, birth,...   \n",
       "5  [Information, about, diarist, Date, of, birth,...   \n",
       "6  [Information, about, diarist, Date, of, birth,...   \n",
       "7  [Information, about, diarist, Date, of, birth,...   \n",
       "8  [Information, about, diarist, Date, of, birth,...   \n",
       "9  [Information, about, diarist, Date, of, birth,...   \n",
       "\n",
       "                                           txt_lower  \\\n",
       "0  [information, about, diarist, date, of, birth,...   \n",
       "1  [information, about, diarist, date, of, birth,...   \n",
       "2  [information, about, diarist, date, of, birth,...   \n",
       "3  [information, about, diarist, date, of, birth,...   \n",
       "4  [information, about, diarist, date, of, birth,...   \n",
       "5  [information, about, diarist, date, of, birth,...   \n",
       "6  [information, about, diarist, date, of, birth,...   \n",
       "7  [information, about, diarist, date, of, birth,...   \n",
       "8  [information, about, diarist, date, of, birth,...   \n",
       "9  [information, about, diarist, date, of, birth,...   \n",
       "\n",
       "                                       spell_checked  \\\n",
       "0  [information, about, diarist, date, of, birth,...   \n",
       "1  [information, about, diarist, date, of, birth,...   \n",
       "2  [information, about, diarist, date, of, birth,...   \n",
       "3  [information, about, diarist, date, of, birth,...   \n",
       "4  [information, about, diarist, date, of, birth,...   \n",
       "5  [information, about, diarist, date, of, birth,...   \n",
       "6  [information, about, diarist, date, of, birth,...   \n",
       "7  [information, about, diarist, date, of, birth,...   \n",
       "8  [information, about, diarist, date, of, birth,...   \n",
       "9  [information, about, diarist, date, of, birth,...   \n",
       "\n",
       "                                            no_punct  \\\n",
       "0  [information, about, diarist, date, of, birth,...   \n",
       "1  [information, about, diarist, date, of, birth,...   \n",
       "2  [information, about, diarist, date, of, birth,...   \n",
       "3  [information, about, diarist, date, of, birth,...   \n",
       "4  [information, about, diarist, date, of, birth,...   \n",
       "5  [information, about, diarist, date, of, birth,...   \n",
       "6  [information, about, diarist, date, of, birth,...   \n",
       "7  [information, about, diarist, date, of, birth,...   \n",
       "8  [information, about, diarist, date, of, birth,...   \n",
       "9  [information, about, diarist, date, of, birth,...   \n",
       "\n",
       "                                   no_punct_no_space  \n",
       "0  [information, about, diarist, date, of, birth,...  \n",
       "1  [information, about, diarist, date, of, birth,...  \n",
       "2  [information, about, diarist, date, of, birth,...  \n",
       "3  [information, about, diarist, date, of, birth,...  \n",
       "4  [information, about, diarist, date, of, birth,...  \n",
       "5  [information, about, diarist, date, of, birth,...  \n",
       "6  [information, about, diarist, date, of, birth,...  \n",
       "7  [information, about, diarist, date, of, birth,...  \n",
       "8  [information, about, diarist, date, of, birth,...  \n",
       "9  [information, about, diarist, date, of, birth,...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foot_mouth_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_mouth_df.loc[10, 'no_punct_no_space']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are cooking with gas (unless that saying is no longer environmentally sustainable? Hmmm. ). \n",
    "\n",
    "But we are not done yet! Next up... Stopwords!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords are typically conjunctions ('and', 'or'), prepositions ('to', 'around'), determiners ('the', 'an'), possessives ('s) and the like. The are **REALLY** common in all languages, and tend to occur at about the same ratio in all kinds of writing, regardless of who did the writing or what it is about. These words are definitely important for structure as they make all the difference between \"Freeze *or* I'll shoot!\" and \"Freeze *and* I'll shoot!\". \n",
    "\n",
    "Buuuut... Many for many text-mining analyses, especially those that take the bag of words approach, these words don't have a whole lot of meaning in and of themselves. Thus, we want to remove them. \n",
    "\n",
    "Let's start by downloading the basic stopwords function built into nltk and storing the English language ones in a list called, appropriately enough, 'stop_words'. \n",
    "\n",
    "Then let's have a look at what is in that list with a print command by doing the whole Run/Shift+Enter thing in the next two (two?!?) code cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/loucap/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(sorted(stop_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________\n",
    "Great. Now let's remove those stop_words by creating another list called corpus_no_stop_words. Then, we iterate over corpus_correct_spell, looking at them one by one and appending them to corpus_no_stop_words if and only if they do not match any of the items in the stop_words list. \n",
    "\n",
    "As you might expect, you should do the whole Run/Shift+Enter thing. Again. (I know, I know...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_mouth_df['no_stop_words'] = foot_mouth_df['no_punct_no_space'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_mouth_df.loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_mouth_df.loc[10,'no_stop_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________\n",
    "Hey now! That looks pretty good. Not perfect, but good. \n",
    "\n",
    "**REMINDER:** Make sure to always convert to lowercase before trying this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidation\n",
    "#### Stemming words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can probably imagine what comes next by now. We import a specific tool from nltk (it is not called the natural language tool kit for nuthin'), define a function, create a fresh new corpus by applying the function to an existing corpus, and print the first hundred items to have a nosey. \n",
    "\n",
    "Go ahead. Run/Shift+Enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "corpus_stemmed = [porter.stem(word) for word in corpus_no_space]\n",
    "print(corpus_stemmed[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "\n",
    "foot_mouth_df['stemmed'] = foot_mouth_df['no_stop_words'].apply(lambda x: [porter.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_mouth_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_mouth_df.loc[10,'stemmed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yayyyy now dont with (data exploration) cleaning - now let's dive into the text-mining!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatisation - IGNORE FOR NOW!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved a whole lot already! This is great work! \n",
    "\n",
    "Now, you will have to think carefully about:\n",
    "- what processes you will need for the analysis you want to run, \n",
    "- what is the right order of processes for your corpus/corpora and your research questions, and \n",
    "- how will you keep track of which processes you run and in which order. Replicability demands clear step-by-steps!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading and resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Books, tutorials, package recommendations, etc. for Python\n",
    "- Programming with Python for Social Scientists. Brooker, 2020. https://study.sagepub.com/brooker\n",
    "- Automate the Boring Stuff with Python: Practical Programming for Total Beginners, Sweigart, 2019. ISBN-13: 9781593279929\n",
    "- SentDex, python programming tutorials on YouTube https://www.youtube.com/user/sentdex\n",
    "- nltk (Natural Language Toolkit) https://www.nltk.org/book/ch01.html\n",
    "- nltk.corpus http://www.nltk.org/howto/corpus.html\n",
    "- spaCy https://nlpforhackers.io/complete-guide-to-spacy/\n",
    "\n",
    "Books and package recommendations for R\n",
    "- Quanteda, an R package for text analysis https://quanteda.io/​\n",
    "- Text Mining with R, a free online book https://www.tidytextmining.com/​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\L_Pel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\L_Pel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                0  \\\n",
      "0           0  5407diary02.rtf   \n",
      "1           1  5407diary03.rtf   \n",
      "2           2  5407diary07.rtf   \n",
      "3           3  5407diary08.rtf   \n",
      "4           4  5407diary09.rtf   \n",
      "5           5  5407diary10.rtf   \n",
      "6           6  5407diary13.rtf   \n",
      "7           7  5407diary14.rtf   \n",
      "8           8  5407diary15.rtf   \n",
      "9           9  5407diary16.rtf   \n",
      "\n",
      "                                                   1  \n",
      "0  \\n\\nInformation about diarist\\nDate of birth: ...  \n",
      "1  Information about diarist\\nDate of birth: 1966...  \n",
      "2  \\n\\nInformation about diarist\\nDate of birth: ...  \n",
      "3  Information about diarist\\nDate of birth: 1963...  \n",
      "4  Information about diarist\\nDate of birth: 1981...  \n",
      "5  Information about diarist\\nDate of birth: 1937...  \n",
      "6  Information about diarist\\nDate of birth: 1947...  \n",
      "7  \\nInformation about diarist\\nDate of birth: 19...  \n",
      "8  Information about diarist\\nDate of birth: 1949...  \n",
      "9  \\nInformation about diarist\\nDate of birth: 19...  \n"
     ]
    }
   ],
   "source": [
    "# It is good practice to always start by importing the modules and packages you will need. \n",
    "\n",
    "import os                         # os is a module for navigating your machine (e.g., file directories).\n",
    "import nltk                       # nltk stands for natural language tool kit and is useful for text-mining. \n",
    "import re                         # re is for regular expressions, which we use later \n",
    "import pandas as pd               # we need pandas to import the foot_mouth_original.xls file\n",
    "! pip install xlrd                # apparently we also need xlrd to read the .xls file because pandas is not old school\n",
    "import xlrd                       # le sigh\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize    # importing the word_tokenize function from nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "foot_mouth_df = pd.read_csv ('../code/data/foot_mouth/text.csv')\n",
    "print (foot_mouth_df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns renamed :)\n",
      " \n",
      "DataFrames Successfully split!\n",
      "Data Column added..\n",
      "Gender column added...\n",
      "Occupation column added...\n",
      " \n",
      " EVERYTHING READY! :)\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\L_Pel\\AppData\\Local\\Temp\\ipykernel_120\\1913629920.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_foot_mouth = diary_file.append(group_int_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Filename</th>\n",
       "      <th>everything_else</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5407diary02.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5407diary03.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1966...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5407diary07.rtf</td>\n",
       "      <td>\\n\\nInformation about diarist\\nDate of birth: ...</td>\n",
       "      <td>6th January 2003</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5407diary08.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1963...</td>\n",
       "      <td>9th March 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5407diary09.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1981...</td>\n",
       "      <td>25th February 2002</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5407diary10.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1937...</td>\n",
       "      <td>11th March 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5407diary13.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1947...</td>\n",
       "      <td>18th March 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5407diary14.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5407diary15.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1949...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5407diary16.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>2000 for 2001</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5407diary17.rtf</td>\n",
       "      <td>Information about diarist\\nDate of birth: 1936...</td>\n",
       "      <td>30th May 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>5407diary18.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>5407diary19.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>4th March 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>5407diary21.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>11 March 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>5407diary22.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>5407diary23.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>24th March 2001</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5407diary24.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5407diary26.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>6th January 2003</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5407diary27.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>5407diary28.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>13 May 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>5407diary29.rtf</td>\n",
       "      <td>\\nInformation about diarist\\nDate of birth: 19...</td>\n",
       "      <td>16th September 2002</td>\n",
       "      <td>M</td>\n",
       "      <td>Group 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number         Filename  \\\n",
       "0        0  5407diary02.rtf   \n",
       "1        1  5407diary03.rtf   \n",
       "2        2  5407diary07.rtf   \n",
       "3        3  5407diary08.rtf   \n",
       "4        4  5407diary09.rtf   \n",
       "5        5  5407diary10.rtf   \n",
       "6        6  5407diary13.rtf   \n",
       "7        7  5407diary14.rtf   \n",
       "8        8  5407diary15.rtf   \n",
       "9        9  5407diary16.rtf   \n",
       "10      10  5407diary17.rtf   \n",
       "11      11  5407diary18.rtf   \n",
       "12      12  5407diary19.rtf   \n",
       "13      13  5407diary21.rtf   \n",
       "14      14  5407diary22.rtf   \n",
       "15      15  5407diary23.rtf   \n",
       "16      16  5407diary24.rtf   \n",
       "17      17  5407diary26.rtf   \n",
       "18      18  5407diary27.rtf   \n",
       "19      19  5407diary28.rtf   \n",
       "20      20  5407diary29.rtf   \n",
       "\n",
       "                                      everything_else                Dates  \\\n",
       "0   \\n\\nInformation about diarist\\nDate of birth: ...                  NaN   \n",
       "1   Information about diarist\\nDate of birth: 1966...                  NaN   \n",
       "2   \\n\\nInformation about diarist\\nDate of birth: ...     6th January 2003   \n",
       "3   Information about diarist\\nDate of birth: 1963...       9th March 2002   \n",
       "4   Information about diarist\\nDate of birth: 1981...   25th February 2002   \n",
       "5   Information about diarist\\nDate of birth: 1937...      11th March 2002   \n",
       "6   Information about diarist\\nDate of birth: 1947...      18th March 2002   \n",
       "7   \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "8   Information about diarist\\nDate of birth: 1949...                  NaN   \n",
       "9   \\nInformation about diarist\\nDate of birth: 19...        2000 for 2001   \n",
       "10  Information about diarist\\nDate of birth: 1936...        30th May 2002   \n",
       "11  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "12  \\nInformation about diarist\\nDate of birth: 19...       4th March 2002   \n",
       "13  \\nInformation about diarist\\nDate of birth: 19...        11 March 2002   \n",
       "14  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "15  \\nInformation about diarist\\nDate of birth: 19...      24th March 2001   \n",
       "16  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "17  \\nInformation about diarist\\nDate of birth: 19...     6th January 2003   \n",
       "18  \\nInformation about diarist\\nDate of birth: 19...                  NaN   \n",
       "19  \\nInformation about diarist\\nDate of birth: 19...          13 May 2002   \n",
       "20  \\nInformation about diarist\\nDate of birth: 19...  16th September 2002   \n",
       "\n",
       "   Gender Occupation  \n",
       "0       M    Group 6  \n",
       "1       F    Group 6  \n",
       "2       F    Group 6  \n",
       "3       M    Group 6  \n",
       "4       F    Group 5  \n",
       "5       M    Group 5  \n",
       "6       M    Group 5  \n",
       "7       F    Group 5  \n",
       "8       F    Group 5  \n",
       "9       M    Group 5  \n",
       "10      M    Group 5  \n",
       "11      F    Group 5  \n",
       "12      M    Group 4  \n",
       "13      M    Group 4  \n",
       "14      F    Group 4  \n",
       "15      M    Group 4  \n",
       "16      M    Group 4  \n",
       "17      M    Group 4  \n",
       "18      F    Group 3  \n",
       "19      M    Group 3  \n",
       "20      M    Group 3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming Columns\n",
    "foot_mouth_df = pd.read_csv ('../code/data/foot_mouth/text.csv') \n",
    "\n",
    "foot_mouth_df.columns = [\"Number\", \"Filename\", \"everything_else\"]\n",
    "foot_mouth_df.head()\n",
    "\n",
    "print(\"Columns renamed :)\")\n",
    "print(\" \")\n",
    "\n",
    "# Splitting DataFrames\n",
    "diary_file = foot_mouth_df.loc[:39]     # Saving variable for all diary rows\n",
    "group_int_file = foot_mouth_df[40:]     # Saving variable for all group and interview rows\n",
    "\n",
    "print(\"DataFrames Successfully split!\")\n",
    "\n",
    "# Adding Data Column\n",
    "\n",
    "diary_file = diary_file.assign(Dates = diary_file['everything_else'].str.extract(r'(\\d{1,2}\\w+\\s+\\w+\\s+\\d{4})'))\n",
    "\n",
    "group_int_file = foot_mouth_df[40:]\n",
    "group_int_file = group_int_file.assign(Dates = group_int_file['everything_else'].str.extract(r'(\\d{2}\\/\\d{2}\\/\\d{2})'))\n",
    "\n",
    "new_foot_mouth = diary_file.append(group_int_file)\n",
    "\n",
    "print(\"Data Column added..\")\n",
    "\n",
    "# Assigning Gender Column then getting rid of the ':'\n",
    "\n",
    "new_foot_mouth = new_foot_mouth.assign(Gender = new_foot_mouth['everything_else'].str.extract('r(\\:\\s*[MF])')) \n",
    "\n",
    "new_foot_mouth['Gender'] = new_foot_mouth['Gender'].astype(str)\n",
    "new_foot_mouth['Gender'] = new_foot_mouth['Gender'].map(lambda x: x.lstrip(':'))\n",
    "\n",
    "print(\"Gender column added...\")\n",
    "\n",
    "#Assigning the Occupation Column\n",
    "\n",
    "new_foot_mouth = new_foot_mouth.assign(Occupation = new_foot_mouth['everything_else'].str.extract(r'(\\w+\\s+\\d{1,2})'))\n",
    "\n",
    "print(\"Occupation column added...\")\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "print(\" EVERYTHING READY! :)\")\n",
    "print(\" \")\n",
    "\n",
    "new_foot_mouth.loc[:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autocorrect in c:\\users\\l_pel\\anaconda3\\lib\\site-packages (2.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Tokenising by word\n",
    "foot_mouth_df['tokenised_words'] = foot_mouth_df.apply(lambda row: nltk.word_tokenize(row['everything_else']), axis=1)\n",
    "\n",
    "#Removing Uppercase\n",
    "foot_mouth_df['txt_lower'] = foot_mouth_df['tokenised_words'].apply(lambda x: [w.lower() for w in x])\n",
    "\n",
    "#Correcting Spelling\n",
    "!pip install autocorrect\n",
    "\n",
    "from autocorrect import Speller\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "foot_mouth_df['spell_checked'] = foot_mouth_df['txt_lower'].apply(lambda x: [spell(w) for w in x])\n",
    "\n",
    "def replacement_mapping(x):\n",
    "        if x == \"der\":\n",
    "            return re.sub(\"der\",\"defra\",x)\n",
    "        else:\n",
    "            return x  \n",
    "\n",
    "def replacement_mapping_2(x):\n",
    "        if x == \"ffd\":\n",
    "            return re.sub(\"ffd\",\"fmd\",x)\n",
    "        else:\n",
    "            return x  \n",
    "foot_mouth_df[\"spell_checked\"] = foot_mouth_df[\"spell_checked\"].apply(lambda x:[replacement_mapping(w) for w in x])\n",
    "foot_mouth_df[\"spell_checked\"] = foot_mouth_df[\"spell_checked\"].apply(lambda x:[replacement_mapping_2(w) for w in x])\n",
    "\n",
    "#Removing Punctuation and getting rid of resulting space\n",
    "English_punctuation = \"!\\\"#$%&()*+,./:;<=>?@[\\]^_`{|}~“”-\"      # Define a variable with all the punctuation to remove.\n",
    "print(English_punctuation)                                     # Print that defined variable, just to check it is correct.\n",
    "print(\"...\") \n",
    "\n",
    "\n",
    "def remove_punctuation(from_text):                           # Had to define a function to iterate over the strings in a row\n",
    "    table = str.maketrans('', '', English_punctuation)       # The python function 'maketrans' creates a table that maps\n",
    "    stripped = [w.translate(table) for w in from_text]        # the punctation marks to 'None'. Print the table to check. \n",
    "    return stripped\n",
    "\n",
    "foot_mouth_df['no_punct'] = [remove_punctuation(i) for i in foot_mouth_df['spell_checked']] # Iterating above function to each\n",
    "\n",
    "foot_mouth_df['no_punct_no_space'] = [list(filter(None, sublist)) for sublist in foot_mouth_df['no_punct']]\n",
    "\n",
    "#Removing Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(sorted(stop_words))\n",
    "foot_mouth_df['no_stop_words'] = foot_mouth_df['no_punct_no_space'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "#Now Stemming!\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "foot_mouth_df['stemmed'] = foot_mouth_df['no_stop_words'].apply(lambda x: [porter.stem(y) for y in x])\n",
    "foot_mouth_df[:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><a href=\"./tm-extraction-2020-06-16.ipynb\" target=_blank><i>Next section: Extracting text</i></a></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
